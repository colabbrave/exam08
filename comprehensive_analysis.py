#!/usr/bin/env python3
"""
æœƒè­°è¨˜éŒ„å„ªåŒ–ç³»çµ± - ç¶œåˆæ€§èƒ½è©•ä¼°å ±å‘Š
åˆ†ææ•´å€‹ç³»çµ±çš„å„ªåŒ–æ•ˆæœã€å•é¡Œè¨ºæ–·èˆ‡æ”¹é€²å»ºè­°
"""

import json
import os
import pandas as pd
import matplotlib.pyplot as plt
import numpy as np
from pathlib import Path
from datetime import datetime
import re

def load_all_scores():
    """è¼‰å…¥æ‰€æœ‰æœƒè­°çš„ç–Šä»£åˆ†æ•¸"""
    results = {}
    iterations_dir = Path('results/iterations')
    
    if not iterations_dir.exists():
        return results
    
    for meeting_dir in iterations_dir.iterdir():
        if meeting_dir.is_dir() and not meeting_dir.name.startswith('tmp'):
            meeting_name = meeting_dir.name
            scores = []
            
            score_files = sorted([f for f in meeting_dir.glob('iteration_*_scores.json')], 
                               key=lambda x: int(x.stem.split('_')[1]))
            
            for score_file in score_files:
                try:
                    with open(score_file, 'r', encoding='utf-8') as f:
                        data = json.load(f)
                        iteration = int(score_file.stem.split('_')[1])
                        
                        if 'scores' in data and 'overall_score' in data['scores']:
                            score = data['scores']['overall_score']
                            strategy = data.get('strategy_combination', [])
                            scores.append({
                                'iteration': iteration,
                                'score': score,
                                'strategy': strategy,
                                'execution_time': data.get('execution_time', 0)
                            })
                except Exception as e:
                    print(f'è­¦å‘Š: ç„¡æ³•è®€å– {score_file}: {e}')
            
            if scores:
                results[meeting_name] = scores
    
    return results

def analyze_early_stopping_effectiveness():
    """åˆ†æ early stopping æ©Ÿåˆ¶çš„æœ‰æ•ˆæ€§"""
    all_scores = load_all_scores()
    analysis = {}
    
    for meeting, scores in all_scores.items():
        if len(scores) < 3:
            continue
            
        score_values = [s['score'] for s in scores]
        
        # è¨ˆç®—æ”¹é€²è¶¨å‹¢
        improvements = []
        for i in range(1, len(score_values)):
            improvements.append(score_values[i] - score_values[i-1])
        
        # æ‰¾åˆ°æœ€å¾Œæœ‰æ•ˆæ”¹é€²
        significant_improvements = [i for i, imp in enumerate(improvements) if imp > 0.01]
        last_improvement_idx = significant_improvements[-1] if significant_improvements else 0
        
        # åˆ†ææ˜¯å¦æ‡‰è©²æ›´æ—©åœæ­¢
        should_stop_at = last_improvement_idx + 3  # patience = 3
        actual_iterations = len(scores)
        
        analysis[meeting] = {
            'actual_iterations': actual_iterations,
            'should_stop_at': min(should_stop_at, actual_iterations),
            'wasted_iterations': max(0, actual_iterations - should_stop_at),
            'last_significant_improvement': last_improvement_idx,
            'final_score': score_values[-1],
            'best_score': max(score_values),
            'best_iteration': score_values.index(max(score_values)),
            'efficiency_ratio': should_stop_at / actual_iterations if actual_iterations > 0 else 0
        }
    
    return analysis

def analyze_strategy_effectiveness():
    """åˆ†æç­–ç•¥çµ„åˆçš„æœ‰æ•ˆæ€§"""
    all_scores = load_all_scores()
    strategy_performance = {}
    
    for meeting, scores in all_scores.items():
        for score_data in scores:
            strategies = tuple(sorted(score_data['strategy']))
            score = score_data['score']
            
            if strategies not in strategy_performance:
                strategy_performance[strategies] = []
            strategy_performance[strategies].append(score)
    
    # è¨ˆç®—æ¯å€‹ç­–ç•¥çµ„åˆçš„çµ±è¨ˆ
    strategy_stats = {}
    for strategies, scores in strategy_performance.items():
        if len(scores) >= 2:  # è‡³å°‘è¦æœ‰2æ¬¡ä½¿ç”¨
            strategy_stats[strategies] = {
                'avg_score': np.mean(scores),
                'std_score': np.std(scores),
                'usage_count': len(scores),
                'max_score': max(scores),
                'min_score': min(scores)
            }
    
    # æ’åºæ‰¾å‡ºæœ€ä½³ç­–ç•¥
    best_strategies = sorted(strategy_stats.items(), 
                           key=lambda x: x[1]['avg_score'], 
                           reverse=True)
    
    return strategy_stats, best_strategies

def analyze_execution_performance():
    """åˆ†æåŸ·è¡Œæ€§èƒ½"""
    all_scores = load_all_scores()
    performance_stats = {}
    
    for meeting, scores in all_scores.items():
        execution_times = [s['execution_time'] for s in scores if s['execution_time'] > 0]
        
        if execution_times:
            performance_stats[meeting] = {
                'avg_time_per_iteration': np.mean(execution_times),
                'total_time': sum(execution_times),
                'min_time': min(execution_times),
                'max_time': max(execution_times),
                'time_efficiency': np.mean(execution_times) / 60  # åˆ†é˜ç‚ºå–®ä½
            }
    
    return performance_stats

def generate_comprehensive_report():
    """ç”Ÿæˆç¶œåˆè©•ä¼°å ±å‘Š"""
    print("=" * 100)
    print("æœƒè­°è¨˜éŒ„å„ªåŒ–ç³»çµ± - ç¶œåˆæ€§èƒ½è©•ä¼°å ±å‘Š")
    print("=" * 100)
    print(f"è©•ä¼°æ™‚é–“: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print(f"è©•ä¼°ç¯„åœ: å®Œæ•´ç³»çµ±é‹è¡Œæ­·å²è¨˜éŒ„")
    print()
    
    # è¼‰å…¥åŸºæœ¬çµ±è¨ˆ
    all_scores = load_all_scores()
    
    print("ğŸ“Š ç³»çµ±æ¦‚è¦½")
    print("-" * 50)
    total_meetings = len(all_scores)
    total_iterations = sum(len(scores) for scores in all_scores.values())
    print(f"   â€¢ è™•ç†æœƒè­°æ•¸é‡: {total_meetings} å ´")
    print(f"   â€¢ ç¸½ç–Šä»£æ¬¡æ•¸: {total_iterations} è¼ª")
    
    if total_iterations > 0:
        avg_iterations = total_iterations / total_meetings
        print(f"   â€¢ å¹³å‡ç–Šä»£æ¬¡æ•¸: {avg_iterations:.1f} è¼ª/æœƒè­°")
    print()
    
    # Early Stopping åˆ†æ
    print("ğŸ›‘ Early Stopping æ©Ÿåˆ¶åˆ†æ")
    print("-" * 50)
    es_analysis = analyze_early_stopping_effectiveness()
    
    total_wasted = sum(a['wasted_iterations'] for a in es_analysis.values())
    avg_efficiency = np.mean([a['efficiency_ratio'] for a in es_analysis.values()])
    
    print(f"   â€¢ ç¸½æµªè²»ç–Šä»£æ¬¡æ•¸: {total_wasted} è¼ª")
    print(f"   â€¢ å¹³å‡æ•ˆç‡æ¯”ç‡: {avg_efficiency:.2%}")
    
    for meeting, analysis in es_analysis.items():
        meeting_short = meeting[:15] + "..." if len(meeting) > 15 else meeting
        print(f"   â€¢ {meeting_short}:")
        print(f"     - å¯¦éš›ç–Šä»£: {analysis['actual_iterations']} è¼ª")
        print(f"     - å»ºè­°åœæ­¢æ–¼: ç¬¬{analysis['should_stop_at']} è¼ª")
        print(f"     - æµªè²»ç–Šä»£: {analysis['wasted_iterations']} è¼ª")
        print(f"     - æœ€ä½³åˆ†æ•¸åœ¨: ç¬¬{analysis['best_iteration']} è¼ª ({analysis['best_score']:.4f})")
    print()
    
    # ç­–ç•¥æ•ˆæœåˆ†æ
    print("ğŸ¯ ç­–ç•¥çµ„åˆæ•ˆæœåˆ†æ")
    print("-" * 50)
    strategy_stats, best_strategies = analyze_strategy_effectiveness()
    
    print(f"   â€¢ ç¸½æ¸¬è©¦ç­–ç•¥çµ„åˆ: {len(strategy_stats)} ç¨®")
    print(f"   â€¢ æœ‰æ•ˆç­–ç•¥çµ„åˆ (>=2æ¬¡ä½¿ç”¨): {len(best_strategies)} ç¨®")
    print()
    print("   ğŸ† å‰5åæœ€ä½³ç­–ç•¥çµ„åˆ:")
    
    for i, (strategies, stats) in enumerate(best_strategies[:5]):
        strategy_names = [s.split('_')[-1] for s in strategies]
        print(f"   {i+1}. {' + '.join(strategy_names)}")
        print(f"      å¹³å‡åˆ†æ•¸: {stats['avg_score']:.4f} (Â±{stats['std_score']:.4f})")
        print(f"      ä½¿ç”¨æ¬¡æ•¸: {stats['usage_count']} æ¬¡")
        print(f"      åˆ†æ•¸ç¯„åœ: {stats['min_score']:.4f} ~ {stats['max_score']:.4f}")
    print()
    
    # åŸ·è¡Œæ€§èƒ½åˆ†æ
    print("âš¡ åŸ·è¡Œæ€§èƒ½åˆ†æ")
    print("-" * 50)
    perf_stats = analyze_execution_performance()
    
    if perf_stats:
        avg_times = [stats['avg_time_per_iteration'] for stats in perf_stats.values()]
        total_times = [stats['total_time'] for stats in perf_stats.values()]
        
        print(f"   â€¢ å¹³å‡æ¯è¼ªè€—æ™‚: {np.mean(avg_times):.1f} ç§’")
        print(f"   â€¢ å¹³å‡ç¸½è™•ç†æ™‚é–“: {np.mean(total_times)/60:.1f} åˆ†é˜/æœƒè­°")
        print(f"   â€¢ æœ€å¿«è™•ç†æ™‚é–“: {min(total_times)/60:.1f} åˆ†é˜")
        print(f"   â€¢ æœ€æ…¢è™•ç†æ™‚é–“: {max(total_times)/60:.1f} åˆ†é˜")
    print()
    
    # å•é¡Œè¨ºæ–·
    print("ğŸ” å•é¡Œè¨ºæ–·")
    print("-" * 50)
    
    major_issues = []
    
    # æª¢æŸ¥éåº¦ç–Šä»£
    if total_wasted > total_iterations * 0.3:
        major_issues.append("âŒ åš´é‡çš„éåº¦ç–Šä»£å•é¡Œ")
        print("   âŒ åš´é‡çš„éåº¦ç–Šä»£å•é¡Œ")
        print("      - è¶…é30%çš„ç–Šä»£æ˜¯ä¸å¿…è¦çš„")
        print("      - early stopping æ©Ÿåˆ¶éœ€è¦èª¿æ•´")
    
    # æª¢æŸ¥åˆ†æ•¸æ³¢å‹•
    volatile_meetings = []
    for meeting, scores in all_scores.items():
        score_values = [s['score'] for s in scores]
        if len(score_values) > 3:
            volatility = np.std(score_values)
            if volatility > 0.15:
                volatile_meetings.append((meeting, volatility))
    
    if len(volatile_meetings) > 0:
        major_issues.append("âŒ åˆ†æ•¸æ³¢å‹•éå¤§")
        print("   âŒ åˆ†æ•¸æ³¢å‹•éå¤§")
        print("      - ä»¥ä¸‹æœƒè­°åˆ†æ•¸ä¸ç©©å®š:")
        for meeting, vol in volatile_meetings[:3]:
            meeting_short = meeting[:20] + "..." if len(meeting) > 20 else meeting
            print(f"        â€¢ {meeting_short}: Ïƒ={vol:.4f}")
    
    # æª¢æŸ¥æ•´é«”æ”¹å–„æ•ˆæœ
    improvement_rates = []
    for meeting, scores in all_scores.items():
        if len(scores) >= 2:
            score_values = [s['score'] for s in scores]
            improvement = (score_values[-1] - score_values[0]) / score_values[0]
            improvement_rates.append(improvement)
    
    if improvement_rates:
        avg_improvement = np.mean(improvement_rates)
        if avg_improvement < 0:
            major_issues.append("âŒ æ•´é«”å“è³ªä¸‹é™")
            print("   âŒ æ•´é«”å“è³ªä¸‹é™")
            print(f"      - å¹³å‡æ”¹å–„ç‡: {avg_improvement:.2%}")
            print("      - ç³»çµ±å¯èƒ½å­˜åœ¨æ ¹æœ¬æ€§å•é¡Œ")
    
    if not major_issues:
        print("   âœ… æœªç™¼ç¾é‡å¤§å•é¡Œ")
    print()
    
    # æ”¹é€²å»ºè­°
    print("ğŸ’¡ ç³»çµ±æ”¹é€²å»ºè­°")
    print("-" * 50)
    
    priority_suggestions = []
    
    if total_wasted > total_iterations * 0.2:
        priority_suggestions.append({
            'priority': 'é«˜',
            'category': 'æ•ˆç‡å„ªåŒ–',
            'suggestion': 'èª¿æ•´ early stopping åƒæ•¸',
            'details': [
                'å°‡ patience è¨­ç‚º 3-5 è¼ª',
                'æé«˜ min_improvement é–¾å€¼è‡³ 0.01',
                'æ·»åŠ é€£çºŒä¸‹é™æª¢æ¸¬æ©Ÿåˆ¶'
            ]
        })
    
    if len(volatile_meetings) > 0:
        priority_suggestions.append({
            'priority': 'é«˜',
            'category': 'ç©©å®šæ€§æ”¹å–„',
            'suggestion': 'å„ªåŒ–è©•ä¼°æŒ‡æ¨™',
            'details': [
                'æª¢æŸ¥ BERTScore è¨ˆç®—çš„ä¸€è‡´æ€§',
                'è€ƒæ…®ä½¿ç”¨å¤šæŒ‡æ¨™åŠ æ¬Šå¹³å‡',
                'æ·»åŠ åˆ†æ•¸å¹³æ»‘æ©Ÿåˆ¶'
            ]
        })
    
    if avg_improvement < 0:
        priority_suggestions.append({
            'priority': 'ç·Šæ€¥',
            'category': 'ç­–ç•¥å„ªåŒ–',
            'suggestion': 'é‡æ–°è¨­è¨ˆç­–ç•¥é¸æ“‡æ©Ÿåˆ¶',
            'details': [
                'åˆ†æ LLM æ”¹é€²å»ºè­°çš„å“è³ª',
                'å„ªåŒ–ç­–ç•¥çµ„åˆé‚è¼¯',
                'æ·»åŠ ç­–ç•¥æ•ˆæœé æ¸¬æ©Ÿåˆ¶'
            ]
        })
    
    # æ ¹æ“šæœ€ä½³ç­–ç•¥æä¾›å»ºè­°
    if best_strategies:
        top_strategy = best_strategies[0][0]
        priority_suggestions.append({
            'priority': 'ä¸­',
            'category': 'ç­–ç•¥æ‡‰ç”¨',
            'suggestion': 'å„ªå…ˆä½¿ç”¨é«˜æ•ˆç­–ç•¥çµ„åˆ',
            'details': [
                f'æ¨è–¦ä½¿ç”¨: {" + ".join([s.split("_")[-1] for s in top_strategy])}',
                f'è©²çµ„åˆå¹³å‡åˆ†æ•¸: {best_strategies[0][1]["avg_score"]:.4f}',
                'è€ƒæ…®è¨­ç‚ºé è¨­ç­–ç•¥çµ„åˆ'
            ]
        })
    
    for i, suggestion in enumerate(priority_suggestions, 1):
        print(f"{i}. [{suggestion['priority']}å„ªå…ˆç´š] {suggestion['category']}: {suggestion['suggestion']}")
        for detail in suggestion['details']:
            print(f"   â€¢ {detail}")
        print()
    
    # å»ºè­°ç³»çµ±åƒæ•¸èª¿æ•´
    print("âš™ï¸  å»ºè­°ç³»çµ±åƒæ•¸èª¿æ•´")
    print("-" * 50)
    
    # åŸºæ–¼åˆ†æçµæœè¨ˆç®—å»ºè­°åƒæ•¸
    if es_analysis:
        avg_best_iteration = np.mean([a['best_iteration'] for a in es_analysis.values()])
        suggested_patience = max(3, int(avg_best_iteration * 0.3))
        
        print("config/system_config.json å»ºè­°ä¿®æ”¹:")
        print(f'  "patience": {min(suggested_patience, 8)},')
        print(f'  "min_improvement": 0.01,')
        print(f'  "quality_threshold": 0.6,')
        print(f'  "max_iterations": {int(avg_best_iteration * 1.5)},')
    
    return {
        'total_meetings': total_meetings,
        'total_iterations': total_iterations,
        'early_stopping_analysis': es_analysis,
        'strategy_analysis': strategy_stats,
        'performance_analysis': perf_stats,
        'major_issues': major_issues,
        'suggestions': priority_suggestions
    }

if __name__ == "__main__":
    # ç¢ºä¿åœ¨æ­£ç¢ºçš„å·¥ä½œç›®éŒ„
    if not os.path.exists('results/iterations'):
        print("éŒ¯èª¤: æœªæ‰¾åˆ° results/iterations ç›®éŒ„")
        print("è«‹ç¢ºä¿åœ¨å°ˆæ¡ˆæ ¹ç›®éŒ„åŸ·è¡Œæ­¤è…³æœ¬")
        exit(1)
    
    # åŸ·è¡Œç¶œåˆåˆ†æ
    analysis_results = generate_comprehensive_report()
    
    # ä¿å­˜åˆ†æçµæœ (è½‰æ›ç­–ç•¥åˆ†æçš„tuple keysç‚ºå­—ç¬¦ä¸²)
    analysis_results_serializable = analysis_results.copy()
    if 'strategy_analysis' in analysis_results_serializable:
        strategy_analysis_str = {}
        for k, v in analysis_results_serializable['strategy_analysis'].items():
            key_str = ' + '.join(k) if isinstance(k, tuple) else str(k)
            strategy_analysis_str[key_str] = v
        analysis_results_serializable['strategy_analysis'] = strategy_analysis_str
    
    with open('results/comprehensive_analysis.json', 'w', encoding='utf-8') as f:
        json.dump(analysis_results_serializable, f, ensure_ascii=False, indent=2, default=str)
    
    print("âœ… ç¶œåˆè©•ä¼°å®Œæˆï¼")
    print("ğŸ“ åˆ†æçµæœå·²ä¿å­˜è‡³: results/comprehensive_analysis.json")
