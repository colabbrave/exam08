{
  "timestamp": "20250528_140438",
  "model": "gemma3:4b",
  "iterations": 6,
  "duration_seconds": 17.461660146713257,
  "best_score": 0.4199999999999998,
  "best_template": "",
  "stability_threshold": 0.7,
  "results": {
    "stability_score": 0.6999999999999997,
    "quality_score": 0.0,
    "overall_score": 0.4199999999999998,
    "metrics": {
      "stability_score": 0.6999999999999997,
      "quality_score": 0.0,
      "overall_score": 0.4199999999999998,
      "stability_metrics": {
        "format_consistency": 0.9999999999999997,
        "length_stability": 1.0,
        "key_element_coverage": 0.0,
        "semantic_stability": 0.9999999999999992,
        "overall_stability": 0.6999999999999997
      },
      "quality_metrics": {
        "categories": {
          "semantic_similarity": {
            "name": "semantic_similarity",
            "score": 0.0,
            "metrics": {
              "bertscore_f1": {
                "score": 0.0,
                "weight": 1.0,
                "details": {
                  "error": "unhashable type: 'list'"
                }
              }
            }
          },
          "content_coverage": {
            "name": "content_coverage",
            "score": 0.0,
            "metrics": {
              "rouge1": {
                "score": 0.0,
                "weight": 0.3,
                "details": {
                  "error": "'list' object has no attribute 'lower'"
                }
              },
              "rouge2": {
                "score": 0.0,
                "weight": 0.4,
                "details": {
                  "error": "'list' object has no attribute 'lower'"
                }
              },
              "rougeL": {
                "score": 0.0,
                "weight": 0.3,
                "details": {
                  "error": "'list' object has no attribute 'lower'"
                }
              }
            }
          },
          "structure_quality": {
            "name": "structure_quality",
            "score": 0.0,
            "metrics": {
              "section_heading_quality": {
                "score": 0.0,
                "weight": 0.4,
                "details": {
                  "error": "'list' object has no attribute 'split'"
                }
              },
              "paragraph_structure": {
                "score": 0.0,
                "weight": 0.3,
                "details": {
                  "error": "'list' object has no attribute 'split'"
                }
              },
              "list_usage": {
                "score": 0.0,
                "weight": 0.3,
                "details": {
                  "error": "'list' object has no attribute 'split'"
                }
              }
            }
          }
        },
        "overall_score": 0.0
      },
      "generated_samples": [
        "生成的會議記錄（基於模板和參考文本）:\n\n\n參考:\ntorch>=2.0.0\ntransformers>=4.30.0\nevaluate>=0.4.0\nrouge-score>=0.1.2\nbert-score>=0.3.13\ntqdm>=4.65.0\npandas>=1.5.0\nnumpy>=1.24.0\nscikit-learn>=1.2.0",
        "生成的會議記錄（基於模板和參考文本）:\n\n\n參考:\ntorch>=2.0.0\ntransformers>=4.30.0\nevaluate>=0.4.0\nrouge-score>=0.1.2\nbert-score>=0.3.13\ntqdm>=4.65.0\npandas>=1.5.0\nnumpy>=1.24.0\nscikit-learn>=1.2.0",
        "生成的會議記錄（基於模板和參考文本）:\n\n\n參考:\ntorch>=2.0.0\ntransformers>=4.30.0\nevaluate>=0.4.0\nrouge-score>=0.1.2\nbert-score>=0.3.13\ntqdm>=4.65.0\npandas>=1.5.0\nnumpy>=1.24.0\nscikit-learn>=1.2.0"
      ]
    }
  },
  "optimization_history": [
    {
      "iteration": 1,
      "stability_score": 0.40712271137613654,
      "quality_score": 0.0,
      "overall_score": 0.2442736268256819,
      "metrics": {
        "stability_score": 0.40712271137613654,
        "quality_score": 0.0,
        "overall_score": 0.2442736268256819,
        "stability_metrics": {
          "format_consistency": 0.7688477110772943,
          "length_stability": 0.434304620288663,
          "key_element_coverage": 0.05555555555555555,
          "semantic_stability": 0.36470403664274503,
          "overall_stability": 0.40712271137613654
        },
        "quality_metrics": {
          "categories": {
            "semantic_similarity": {
              "name": "semantic_similarity",
              "score": 0.0,
              "metrics": {
                "bertscore_f1": {
                  "score": 0.0,
                  "weight": 1.0,
                  "details": {
                    "error": "unhashable type: 'list'"
                  }
                }
              }
            },
            "content_coverage": {
              "name": "content_coverage",
              "score": 0.0,
              "metrics": {
                "rouge1": {
                  "score": 0.0,
                  "weight": 0.3,
                  "details": {
                    "error": "'list' object has no attribute 'lower'"
                  }
                },
                "rouge2": {
                  "score": 0.0,
                  "weight": 0.4,
                  "details": {
                    "error": "'list' object has no attribute 'lower'"
                  }
                },
                "rougeL": {
                  "score": 0.0,
                  "weight": 0.3,
                  "details": {
                    "error": "'list' object has no attribute 'lower'"
                  }
                }
              }
            },
            "structure_quality": {
              "name": "structure_quality",
              "score": 0.0,
              "metrics": {
                "section_heading_quality": {
                  "score": 0.0,
                  "weight": 0.4,
                  "details": {
                    "error": "'list' object has no attribute 'split'"
                  }
                },
                "paragraph_structure": {
                  "score": 0.0,
                  "weight": 0.3,
                  "details": {
                    "error": "'list' object has no attribute 'split'"
                  }
                },
                "list_usage": {
                  "score": 0.0,
                  "weight": 0.3,
                  "details": {
                    "error": "'list' object has no attribute 'split'"
                  }
                }
              }
            }
          },
          "overall_score": 0.0
        },
        "generated_samples": [
          "生成的會議記錄（基於模板和參考文本）:\n\n\n參考:\ntorch>=2.0.0\ntransformers>=4.30.0\nevaluate>=0.4.0\nrouge-score>=0.1.2\nbert-score>=0.3.13\ntqdm>=4.65.0\npandas>=1.5.0\nnumpy>=1.24.0\nscikit-learn>=1.2.0",
          "生成的會議記錄（基於模板和參考文本）:\n\n\n參考:\ntorch>=2.0.0\ntransformers>=4.30.0\nevaluate>=0.4.0\nrouge-score>=0.1.2\nbert-score>=0.3.13\ntqdm>=4.65.0\npandas>=1.5.0\nnumpy>=1.24.0\nscikit-learn>=1.2.0",
          "生成的會議記錄（基於模板和參考文本）:\n\n\n參考:\n# 會議記錄優化與評估系統\n\n## 專案概述\n\n本專案旨在利用大型語言模型（LLM）來自動優化會議記錄，提高其結構化程度、完整性和可讀性。系統支援多種優化策略，並提供全面的評估框架來衡量優化效果。\n\n## 主要功能\n\n- **多策略優化**：支援多種會議記錄優化策略\n- **多模型支援**：可與多種開源和商業語言模型整合\n- **自動化評估**：提供多種評估指標來衡量優化效果\n- **可擴展架構**：易於添加新的優化策略和評估指標\n\n## 快速開始\n\n### 前置需求\n- Python 3.8+\n- Ollama 服務 (用於運行本地模型)\n\n### 安裝步驟\n\n```bash\n# 1. 克隆存儲庫\ngit clone https://github.com/colabbrave/exam08.git\ncd exam08\n\n# 2. 創建並啟動虛擬環境\npython -m venv venv\nsource venv/bin/activate  # Linux/Mac\n# 或\n# .\\venv\\Scripts\\activate  # Windows\n\n# 3. 安裝依賴\npip install -r requirements.txt\n\n# 4. 下載並啟動 Ollama 模型\nollama pull gemma3:4b  # 或其他支援的模型\n```\n\n### 基本用法\n\n```bash\n# 優化會議記錄\n./run_optimization.sh\n\n# 或指定模型\n./run_optimization.sh --model gemma3:4b\n\n# 評估優化結果\npython scripts/evaluate.py --model gemma3_4b\n```\n\n## 專案結構\n\n```\n.\n├── config/                  # 配置文件\n├── data/                    # 數據目錄\n│   ├── reference/           # 參考會議記錄\n│   └── transcript/          # 原始逐字稿\n├── docu/                    # 文檔\n├── logs/                    # 運行日誌\n├── models/                  # 模型文件\n├── prompts/                 # 提示詞模板\n│   ├── base/                # 基礎提示詞\n│   ├── components/          # 提示詞組件\n│   ├── optimized/           # 優化後的提示詞\n│   └── preloaded/           # 預加載的提示詞\n├── results/                 # 結果輸出\n│   ├── evaluation_reports/  # 評估報告\n│   └── optimized/           # 優化後的會議記錄\n└── scripts/                 # 腳本文件\n    ├── evaluate.py          # 評估腳本\n    ├── optimize.py          # 優化腳本\n    ├── model_manager.py     # 模型管理\n    ├── ollama_manager.py    # Ollama 集成\n    └── select_model.py      # 模型選擇\n```\n\n## 評估結果\n\n### 多指標評估系統\n\n我們實現了全面的多指標評估系統，包含以下主要指標：\n\n#### 1. 語義相似度 (權重 50%)\n- **BERTScore F1**：衡量優化前後文本的語義相似度\n- **平均分數**：0.85\n\n#### 2. 內容覆蓋度 (權重 30%)\n- **ROUGE-1**：unigram 層面的覆蓋度\n- **ROUGE-2**：bigram 層面的覆蓋度\n- **ROUGE-L**：最長公共子序列\n- **平均分數**：0.78\n\n#### 3. 結構化程度 (權重 20%)\n- 章節標題質量\n- 段落結構質量\n- 列表使用適當性\n- **平均分數**：0.82\n\n### 模型表現比較\n\n| 模型 | 綜合得分 | 響應時間 | BERTScore | ROUGE-L |\n|------|---------|---------|-----------|---------|\n| gemma3:4b | 0.85 | 45.2s | 0.88 | 0.75 |\n| llama3-8b | 0.82 | 68.7s | 0.86 | 0.73 |\n| mistral-7b | 0.80 | 52.1s | 0.84 | 0.72 |\n\n### 最佳實踐策略排名\n\n1. **補充省略資訊** (0.92)\n   - 提升內容完整性\n   - 自動補全會議中的隱含資訊\n\n2. **明確標註發言者** (0.89)\n   - 提高可讀性\n   - 便於追蹤討論脈絡\n\n3. **結構化摘要** (0.88)\n   - 提升文件結構化程度\n   - 便於快速瀏覽重點\n\n4. **專業術語標準化** (0.86)\n   - 統一專業術語使用\n   - 提高專業性\n\n5. **標準格式模板** (0.85)\n   - 確保格式一致性\n   - 符合企業規範\n\n> **注意**：詳細評估報告請參考 [評估報告目錄](results/evaluation_reports/)\n\n## 貢獻指南\n\n我們歡迎任何形式的貢獻！以下是參與項目的步驟：\n\n1. Fork 本項目\n2. 創建特性分支 (`git checkout -b feature/amazing-feature`)\n3. 提交更改 (`git commit -m 'Add some amazing feature'`)\n4. 推送到分支 (`git push origin feature/amazing-feature`)\n5. 開啟 Pull Request\n\n### 代碼風格\n- 使用 [Black](https://github.com/psf/black) 進行代碼格式化\n- 使用 [Google 風格的 Python 文檔字符串](https://google.github.io/styleguide/pyguide.html#38-comments-and-docstrings)\n\n### 提交信息規範\n請遵循 [Conventional Commits](https://www.conventionalcommits.org/) 規範：\n- feat: 新功能\n- fix: 修復 bug\n- docs: 文檔更新\n- style: 代碼格式\n- refactor: 代碼重構\n- test: 測試相關\n- chore: 構建過程或輔助工具的變動\n\n## 專案進度\n\n### 完成情況\n\n1. **基本架構建立** ✅ 已完成\n   - 專案目錄結構\n   - 基礎優化流程\n   - 多模型支援\n\n2. **評估系統實現** ✅ 已完成\n   - ✅ 基本評估框架\n   - ✅ BERTScore 實現\n   - ✅ ROUGE 實現\n   - ✅ 多指標整合\n   - ✅ 評估報告生成\n   - ✅ 評估報告優化 (改為結構化數據格式)\n\n### 當前階段\n\n3. **提示工程優化** 🚀 進行中\n   - 大模型輔助提示詞優化\n   - 非監督學習優化循環\n   - 自動化評估與反饋\n\n### 後續計劃\n\n4. **效能優化** ⏳ 未開始\n   - 並行處理優化\n   - 快取機制實現\n   - 資源使用監控\n\n5. **系統整合** ⏳ 未開始\n   - API 服務封裝\n   - 自動化部署流程\n   - 監控告警系統\n\n## 系統需求與優化\n\n### 硬體配置\n\n- **裝置**：MacBook Pro (M4 晶片)\n- **CPU**：10 核心 (4 個效能核心 + 6 個節能核心)\n- **記憶體**：16GB 統一記憶體\n- **GPU**：Apple M4 整合式顯示晶片\n\n### 模型配置\n\n- **基礎模型**：`cwchang/llama3-taide-lx-8b-chat-alpha1:latest`\n  - 使用 4-bit 量化載入\n  - 主要用於會議記錄生成\n\n- **優化模型**：`google/gemma-3-12b`\n  - 使用 4-bit 量化載入\n  - 用於提示詞優化和改進\n\n## 提示工程優化架構\n\n### 核心組件\n\n1. **會議上下文感知模組**\n   - 自動識別會議類型和特徵\n   - 分析參與者角色和互動模式\n   - 提取關鍵決策點和行動項目\n\n2. **分層提示詞引擎**\n   - 感知層：理解會議本質特徵\n   - 策略層：選擇最優記錄策略\n   - 執行層：生成結構化會議記錄\n\n3. **動態策略管理器**\n   - 多種會議類型的專用策略\n   - 上下文感知的模板選擇\n   - 實時策略調整機制\n\n### 技術實現\n\n```python\n# 會議上下文分析示例\nclass MeetingAnalyzer:\n    def analyze(self, meeting_data: dict) -> MeetingContext:\n        context = MeetingContext()\n        context.meeting_type = self._classify_meeting_type(meeting_data)\n        context.participants = self._extract_participants(meeting_data)\n        context.decision_density = self._calculate_decision_density(meeting_data)\n        return context\n```\n\n### 實施路線圖\n\n#### 階段一：基礎架構重構 (2週)\n- [ ] 實現會議上下文感知模組\n- [ ] 開發分層提示詞引擎基礎框架\n- [ ] 創建3種基礎會議類型的適配器\n\n#### 階段二：動態策略實現 (3週)\n- [ ] 實現策略管理器\n- [ ] 開發模板組件系統\n- [ ] 整合上下文感知評估\n\n#### 階段三：自適應優化 (3週)\n- [ ] 實現強化學習優化器\n- [ ] 設置在線學習循環\n- [ ] 集成知識圖譜\n\n### 預期效益\n\n- **更智能的會議理解**：超越表面指標，理解會議本質\n- **動態適配能力**：根據會議類型自動調整記錄策略\n- **持續優化**：通過在線學習不斷改進表現\n- **更好的可解釋性**：清晰的決策過程和優化路徑\n\n### 技術棧\n\n- **核心框架**：Python 3.9+\n- **機器學習**：PyTorch, Transformers, bitsandbytes (4-bit 量化)\n- **NLP工具**：sentence-transformers, NLTK\n- **記憶體優化**：accelerate, vLLM (可選)\n- **監控工具**：psutil, GPUtil\n\n### 記憶體優化策略\n\n1. **模型量化**\n   - 使用 4-bit 量化技術\n   - 動態量化權重矩陣\n   - 啟用 Flash Attention 2 (如支援)\n\n2. **批次處理**\n   - 小批次處理輸入數據\n   - 實現記憶體監控\n   - 動態調整批次大小\n\n3. **快取機制**\n   - 使用 LRU 快取優化結果\n   - 實現提示詞模板快取\n   - 特徵向量快取\n\n4. **資源監控**\n   - 即時監控記憶體使用\n   - 動態降級機制\n   - 自動清理未使用的資源\n\n### 開發原則\n\n1. **資源效率**：優先考慮記憶體和計算效率\n2. **漸進式增強**：先實現核心功能，再逐步優化\n3. **可觀察性**：完善的監控和日誌記錄\n4. **優雅降級**：在資源受限時自動調整功能\n\n### 效能基準\n\n| 任務 | 預期記憶體使用 | 預期處理時間 |\n|------|--------------|------------|\n| 模型載入 | ~8GB | 30-60秒 |\n| 提示詞優化 | ~12GB | 5-15秒/提示 |\n| 批次處理 (n=5) | ~14GB | 20-40秒 |\n\n> **注意**：實際數值可能因系統負載和具體輸入而異\n\n### 已知限制\n\n1. **記憶體限制**：\n   - 同時載入多個大型模型可能導致記憶體不足\n   - 建議一次只載入一個模型進行推理\n\n2. **處理時間**：\n   - 複雜提示詞可能需要更長處理時間\n   - 批次處理時延遲會增加\n\n3. **建議的最佳實踐**：\n   - 實現請求佇列系統\n   - 設定處理超時機制\n   - 定期重啟長時間運行的程序以釋放記憶體\n\n## 最近更新\n\n### 2025-05-28 (最新)\n- 重構提示工程優化架構\n- 實現分層提示詞引擎\n- 新增會議上下文感知模組\n- 設計動態策略管理系統\n- 更新實施路線圖\n\n### 2025-05-27\n- 更新 README 文件，改進文檔結構和內容完整性\n- 修復評估階段文件路徑比對問題\n- 優化模型名稱處理邏輯，支援不同格式的模型名稱\n- 改進評估腳本，可選擇性評估特定模型的結果\n- 更新 `run_optimization.sh` 腳本，確保正確傳遞模型參數\n- 改進錯誤處理和日誌記錄\n- 新增模型執行時間統計功能\n- 新增策略執行時間統計功能\n- 添加 `run_all_models.sh` 腳本用於批量運行多個模型\n\n### 2025-05-27\n- 新增模型執行時間統計功能\n- 新增策略執行時間統計功能\n- 改進模型名稱處理邏輯\n- 優化錯誤處理和重試機制\n- 添加 `run_all_models.sh` 腳本用於批量運行多個模型\n\n### 2025-05-26\n- 實現模型響應時間追蹤\n- 優化模型調用過程中的錯誤處理\n- 改進重試機制，提高穩定性\n\n### 2025-05-25\n- 修復 `time` 模組導入問題\n- 修正 `model_timings` 和 `strategy_timings` 變數作用域問題\n- 更新評估結果和改進策略\n\n## 授權\n\n本項目採用 [MIT 許可證](LICENSE) 授權。"
        ]
      },
      "timestamp": "2025-05-28T14:04:28.008822"
    },
    {
      "iteration": 2,
      "stability_score": 0.4564134787185976,
      "quality_score": 0.0,
      "overall_score": 0.27384808723115855,
      "metrics": {
        "stability_score": 0.4564134787185976,
        "quality_score": 0.0,
        "overall_score": 0.27384808723115855,
        "stability_metrics": {
          "format_consistency": 0.7688477110772943,
          "length_stability": 0.5959339032443975,
          "key_element_coverage": 0.1111111111111111,
          "semantic_stability": 0.3661952570659825,
          "overall_stability": 0.4564134787185976
        },
        "quality_metrics": {
          "categories": {
            "semantic_similarity": {
              "name": "semantic_similarity",
              "score": 0.0,
              "metrics": {
                "bertscore_f1": {
                  "score": 0.0,
                  "weight": 1.0,
                  "details": {
                    "error": "unhashable type: 'list'"
                  }
                }
              }
            },
            "content_coverage": {
              "name": "content_coverage",
              "score": 0.0,
              "metrics": {
                "rouge1": {
                  "score": 0.0,
                  "weight": 0.3,
                  "details": {
                    "error": "'list' object has no attribute 'lower'"
                  }
                },
                "rouge2": {
                  "score": 0.0,
                  "weight": 0.4,
                  "details": {
                    "error": "'list' object has no attribute 'lower'"
                  }
                },
                "rougeL": {
                  "score": 0.0,
                  "weight": 0.3,
                  "details": {
                    "error": "'list' object has no attribute 'lower'"
                  }
                }
              }
            },
            "structure_quality": {
              "name": "structure_quality",
              "score": 0.0,
              "metrics": {
                "section_heading_quality": {
                  "score": 0.0,
                  "weight": 0.4,
                  "details": {
                    "error": "'list' object has no attribute 'split'"
                  }
                },
                "paragraph_structure": {
                  "score": 0.0,
                  "weight": 0.3,
                  "details": {
                    "error": "'list' object has no attribute 'split'"
                  }
                },
                "list_usage": {
                  "score": 0.0,
                  "weight": 0.3,
                  "details": {
                    "error": "'list' object has no attribute 'split'"
                  }
                }
              }
            }
          },
          "overall_score": 0.0
        },
        "generated_samples": [
          "生成的會議記錄（基於模板和參考文本）:\n\n\n參考:\n# 會議記錄優化與評估系統\n\n## 專案概述\n\n本專案旨在利用大型語言模型（LLM）來自動優化會議記錄，提高其結構化程度、完整性和可讀性。系統支援多種優化策略，並提供全面的評估框架來衡量優化效果。\n\n## 主要功能\n\n- **多策略優化**：支援多種會議記錄優化策略\n- **多模型支援**：可與多種開源和商業語言模型整合\n- **自動化評估**：提供多種評估指標來衡量優化效果\n- **可擴展架構**：易於添加新的優化策略和評估指標\n\n## 快速開始\n\n### 前置需求\n- Python 3.8+\n- Ollama 服務 (用於運行本地模型)\n\n### 安裝步驟\n\n```bash\n# 1. 克隆存儲庫\ngit clone https://github.com/colabbrave/exam08.git\ncd exam08\n\n# 2. 創建並啟動虛擬環境\npython -m venv venv\nsource venv/bin/activate  # Linux/Mac\n# 或\n# .\\venv\\Scripts\\activate  # Windows\n\n# 3. 安裝依賴\npip install -r requirements.txt\n\n# 4. 下載並啟動 Ollama 模型\nollama pull gemma3:4b  # 或其他支援的模型\n```\n\n### 基本用法\n\n```bash\n# 優化會議記錄\n./run_optimization.sh\n\n# 或指定模型\n./run_optimization.sh --model gemma3:4b\n\n# 評估優化結果\npython scripts/evaluate.py --model gemma3_4b\n```\n\n## 專案結構\n\n```\n.\n├── config/                  # 配置文件\n├── data/                    # 數據目錄\n│   ├── reference/           # 參考會議記錄\n│   └── transcript/          # 原始逐字稿\n├── docu/                    # 文檔\n├── logs/                    # 運行日誌\n├── models/                  # 模型文件\n├── prompts/                 # 提示詞模板\n│   ├── base/                # 基礎提示詞\n│   ├── components/          # 提示詞組件\n│   ├── optimized/           # 優化後的提示詞\n│   └── preloaded/           # 預加載的提示詞\n├── results/                 # 結果輸出\n│   ├── evaluation_reports/  # 評估報告\n│   └── optimized/           # 優化後的會議記錄\n└── scripts/                 # 腳本文件\n    ├── evaluate.py          # 評估腳本\n    ├── optimize.py          # 優化腳本\n    ├── model_manager.py     # 模型管理\n    ├── ollama_manager.py    # Ollama 集成\n    └── select_model.py      # 模型選擇\n```\n\n## 評估結果\n\n### 多指標評估系統\n\n我們實現了全面的多指標評估系統，包含以下主要指標：\n\n#### 1. 語義相似度 (權重 50%)\n- **BERTScore F1**：衡量優化前後文本的語義相似度\n- **平均分數**：0.85\n\n#### 2. 內容覆蓋度 (權重 30%)\n- **ROUGE-1**：unigram 層面的覆蓋度\n- **ROUGE-2**：bigram 層面的覆蓋度\n- **ROUGE-L**：最長公共子序列\n- **平均分數**：0.78\n\n#### 3. 結構化程度 (權重 20%)\n- 章節標題質量\n- 段落結構質量\n- 列表使用適當性\n- **平均分數**：0.82\n\n### 模型表現比較\n\n| 模型 | 綜合得分 | 響應時間 | BERTScore | ROUGE-L |\n|------|---------|---------|-----------|---------|\n| gemma3:4b | 0.85 | 45.2s | 0.88 | 0.75 |\n| llama3-8b | 0.82 | 68.7s | 0.86 | 0.73 |\n| mistral-7b | 0.80 | 52.1s | 0.84 | 0.72 |\n\n### 最佳實踐策略排名\n\n1. **補充省略資訊** (0.92)\n   - 提升內容完整性\n   - 自動補全會議中的隱含資訊\n\n2. **明確標註發言者** (0.89)\n   - 提高可讀性\n   - 便於追蹤討論脈絡\n\n3. **結構化摘要** (0.88)\n   - 提升文件結構化程度\n   - 便於快速瀏覽重點\n\n4. **專業術語標準化** (0.86)\n   - 統一專業術語使用\n   - 提高專業性\n\n5. **標準格式模板** (0.85)\n   - 確保格式一致性\n   - 符合企業規範\n\n> **注意**：詳細評估報告請參考 [評估報告目錄](results/evaluation_reports/)\n\n## 貢獻指南\n\n我們歡迎任何形式的貢獻！以下是參與項目的步驟：\n\n1. Fork 本項目\n2. 創建特性分支 (`git checkout -b feature/amazing-feature`)\n3. 提交更改 (`git commit -m 'Add some amazing feature'`)\n4. 推送到分支 (`git push origin feature/amazing-feature`)\n5. 開啟 Pull Request\n\n### 代碼風格\n- 使用 [Black](https://github.com/psf/black) 進行代碼格式化\n- 使用 [Google 風格的 Python 文檔字符串](https://google.github.io/styleguide/pyguide.html#38-comments-and-docstrings)\n\n### 提交信息規範\n請遵循 [Conventional Commits](https://www.conventionalcommits.org/) 規範：\n- feat: 新功能\n- fix: 修復 bug\n- docs: 文檔更新\n- style: 代碼格式\n- refactor: 代碼重構\n- test: 測試相關\n- chore: 構建過程或輔助工具的變動\n\n## 專案進度\n\n### 完成情況\n\n1. **基本架構建立** ✅ 已完成\n   - 專案目錄結構\n   - 基礎優化流程\n   - 多模型支援\n\n2. **評估系統實現** ✅ 已完成\n   - ✅ 基本評估框架\n   - ✅ BERTScore 實現\n   - ✅ ROUGE 實現\n   - ✅ 多指標整合\n   - ✅ 評估報告生成\n   - ✅ 評估報告優化 (改為結構化數據格式)\n\n### 當前階段\n\n3. **提示工程優化** 🚀 進行中\n   - 大模型輔助提示詞優化\n   - 非監督學習優化循環\n   - 自動化評估與反饋\n\n### 後續計劃\n\n4. **效能優化** ⏳ 未開始\n   - 並行處理優化\n   - 快取機制實現\n   - 資源使用監控\n\n5. **系統整合** ⏳ 未開始\n   - API 服務封裝\n   - 自動化部署流程\n   - 監控告警系統\n\n## 系統需求與優化\n\n### 硬體配置\n\n- **裝置**：MacBook Pro (M4 晶片)\n- **CPU**：10 核心 (4 個效能核心 + 6 個節能核心)\n- **記憶體**：16GB 統一記憶體\n- **GPU**：Apple M4 整合式顯示晶片\n\n### 模型配置\n\n- **基礎模型**：`cwchang/llama3-taide-lx-8b-chat-alpha1:latest`\n  - 使用 4-bit 量化載入\n  - 主要用於會議記錄生成\n\n- **優化模型**：`google/gemma-3-12b`\n  - 使用 4-bit 量化載入\n  - 用於提示詞優化和改進\n\n## 提示工程優化架構\n\n### 核心組件\n\n1. **會議上下文感知模組**\n   - 自動識別會議類型和特徵\n   - 分析參與者角色和互動模式\n   - 提取關鍵決策點和行動項目\n\n2. **分層提示詞引擎**\n   - 感知層：理解會議本質特徵\n   - 策略層：選擇最優記錄策略\n   - 執行層：生成結構化會議記錄\n\n3. **動態策略管理器**\n   - 多種會議類型的專用策略\n   - 上下文感知的模板選擇\n   - 實時策略調整機制\n\n### 技術實現\n\n```python\n# 會議上下文分析示例\nclass MeetingAnalyzer:\n    def analyze(self, meeting_data: dict) -> MeetingContext:\n        context = MeetingContext()\n        context.meeting_type = self._classify_meeting_type(meeting_data)\n        context.participants = self._extract_participants(meeting_data)\n        context.decision_density = self._calculate_decision_density(meeting_data)\n        return context\n```\n\n### 實施路線圖\n\n#### 階段一：基礎架構重構 (2週)\n- [ ] 實現會議上下文感知模組\n- [ ] 開發分層提示詞引擎基礎框架\n- [ ] 創建3種基礎會議類型的適配器\n\n#### 階段二：動態策略實現 (3週)\n- [ ] 實現策略管理器\n- [ ] 開發模板組件系統\n- [ ] 整合上下文感知評估\n\n#### 階段三：自適應優化 (3週)\n- [ ] 實現強化學習優化器\n- [ ] 設置在線學習循環\n- [ ] 集成知識圖譜\n\n### 預期效益\n\n- **更智能的會議理解**：超越表面指標，理解會議本質\n- **動態適配能力**：根據會議類型自動調整記錄策略\n- **持續優化**：通過在線學習不斷改進表現\n- **更好的可解釋性**：清晰的決策過程和優化路徑\n\n### 技術棧\n\n- **核心框架**：Python 3.9+\n- **機器學習**：PyTorch, Transformers, bitsandbytes (4-bit 量化)\n- **NLP工具**：sentence-transformers, NLTK\n- **記憶體優化**：accelerate, vLLM (可選)\n- **監控工具**：psutil, GPUtil\n\n### 記憶體優化策略\n\n1. **模型量化**\n   - 使用 4-bit 量化技術\n   - 動態量化權重矩陣\n   - 啟用 Flash Attention 2 (如支援)\n\n2. **批次處理**\n   - 小批次處理輸入數據\n   - 實現記憶體監控\n   - 動態調整批次大小\n\n3. **快取機制**\n   - 使用 LRU 快取優化結果\n   - 實現提示詞模板快取\n   - 特徵向量快取\n\n4. **資源監控**\n   - 即時監控記憶體使用\n   - 動態降級機制\n   - 自動清理未使用的資源\n\n### 開發原則\n\n1. **資源效率**：優先考慮記憶體和計算效率\n2. **漸進式增強**：先實現核心功能，再逐步優化\n3. **可觀察性**：完善的監控和日誌記錄\n4. **優雅降級**：在資源受限時自動調整功能\n\n### 效能基準\n\n| 任務 | 預期記憶體使用 | 預期處理時間 |\n|------|--------------|------------|\n| 模型載入 | ~8GB | 30-60秒 |\n| 提示詞優化 | ~12GB | 5-15秒/提示 |\n| 批次處理 (n=5) | ~14GB | 20-40秒 |\n\n> **注意**：實際數值可能因系統負載和具體輸入而異\n\n### 已知限制\n\n1. **記憶體限制**：\n   - 同時載入多個大型模型可能導致記憶體不足\n   - 建議一次只載入一個模型進行推理\n\n2. **處理時間**：\n   - 複雜提示詞可能需要更長處理時間\n   - 批次處理時延遲會增加\n\n3. **建議的最佳實踐**：\n   - 實現請求佇列系統\n   - 設定處理超時機制\n   - 定期重啟長時間運行的程序以釋放記憶體\n\n## 最近更新\n\n### 2025-05-28 (最新)\n- 重構提示工程優化架構\n- 實現分層提示詞引擎\n- 新增會議上下文感知模組\n- 設計動態策略管理系統\n- 更新實施路線圖\n\n### 2025-05-27\n- 更新 README 文件，改進文檔結構和內容完整性\n- 修復評估階段文件路徑比對問題\n- 優化模型名稱處理邏輯，支援不同格式的模型名稱\n- 改進評估腳本，可選擇性評估特定模型的結果\n- 更新 `run_optimization.sh` 腳本，確保正確傳遞模型參數\n- 改進錯誤處理和日誌記錄\n- 新增模型執行時間統計功能\n- 新增策略執行時間統計功能\n- 添加 `run_all_models.sh` 腳本用於批量運行多個模型\n\n### 2025-05-27\n- 新增模型執行時間統計功能\n- 新增策略執行時間統計功能\n- 改進模型名稱處理邏輯\n- 優化錯誤處理和重試機制\n- 添加 `run_all_models.sh` 腳本用於批量運行多個模型\n\n### 2025-05-26\n- 實現模型響應時間追蹤\n- 優化模型調用過程中的錯誤處理\n- 改進重試機制，提高穩定性\n\n### 2025-05-25\n- 修復 `time` 模組導入問題\n- 修正 `model_timings` 和 `strategy_timings` 變數作用域問題\n- 更新評估結果和改進策略\n\n## 授權\n\n本項目採用 [MIT 許可證](LICENSE) 授權。",
          "生成的會議記錄（基於模板和參考文本）:\n\n\n參考:\ntorch>=2.0.0\ntransformers>=4.30.0\nevaluate>=0.4.0\nrouge-score>=0.1.2\nbert-score>=0.3.13\ntqdm>=4.65.0\npandas>=1.5.0\nnumpy>=1.24.0\nscikit-learn>=1.2.0",
          "生成的會議記錄（基於模板和參考文本）:\n\n\n參考:\n# 會議記錄優化與評估系統\n\n## 專案概述\n\n本專案旨在利用大型語言模型（LLM）來自動優化會議記錄，提高其結構化程度、完整性和可讀性。系統支援多種優化策略，並提供全面的評估框架來衡量優化效果。\n\n## 主要功能\n\n- **多策略優化**：支援多種會議記錄優化策略\n- **多模型支援**：可與多種開源和商業語言模型整合\n- **自動化評估**：提供多種評估指標來衡量優化效果\n- **可擴展架構**：易於添加新的優化策略和評估指標\n\n## 快速開始\n\n### 前置需求\n- Python 3.8+\n- Ollama 服務 (用於運行本地模型)\n\n### 安裝步驟\n\n```bash\n# 1. 克隆存儲庫\ngit clone https://github.com/colabbrave/exam08.git\ncd exam08\n\n# 2. 創建並啟動虛擬環境\npython -m venv venv\nsource venv/bin/activate  # Linux/Mac\n# 或\n# .\\venv\\Scripts\\activate  # Windows\n\n# 3. 安裝依賴\npip install -r requirements.txt\n\n# 4. 下載並啟動 Ollama 模型\nollama pull gemma3:4b  # 或其他支援的模型\n```\n\n### 基本用法\n\n```bash\n# 優化會議記錄\n./run_optimization.sh\n\n# 或指定模型\n./run_optimization.sh --model gemma3:4b\n\n# 評估優化結果\npython scripts/evaluate.py --model gemma3_4b\n```\n\n## 專案結構\n\n```\n.\n├── config/                  # 配置文件\n├── data/                    # 數據目錄\n│   ├── reference/           # 參考會議記錄\n│   └── transcript/          # 原始逐字稿\n├── docu/                    # 文檔\n├── logs/                    # 運行日誌\n├── models/                  # 模型文件\n├── prompts/                 # 提示詞模板\n│   ├── base/                # 基礎提示詞\n│   ├── components/          # 提示詞組件\n│   ├── optimized/           # 優化後的提示詞\n│   └── preloaded/           # 預加載的提示詞\n├── results/                 # 結果輸出\n│   ├── evaluation_reports/  # 評估報告\n│   └── optimized/           # 優化後的會議記錄\n└── scripts/                 # 腳本文件\n    ├── evaluate.py          # 評估腳本\n    ├── optimize.py          # 優化腳本\n    ├── model_manager.py     # 模型管理\n    ├── ollama_manager.py    # Ollama 集成\n    └── select_model.py      # 模型選擇\n```\n\n## 評估結果\n\n### 多指標評估系統\n\n我們實現了全面的多指標評估系統，包含以下主要指標：\n\n#### 1. 語義相似度 (權重 50%)\n- **BERTScore F1**：衡量優化前後文本的語義相似度\n- **平均分數**：0.85\n\n#### 2. 內容覆蓋度 (權重 30%)\n- **ROUGE-1**：unigram 層面的覆蓋度\n- **ROUGE-2**：bigram 層面的覆蓋度\n- **ROUGE-L**：最長公共子序列\n- **平均分數**：0.78\n\n#### 3. 結構化程度 (權重 20%)\n- 章節標題質量\n- 段落結構質量\n- 列表使用適當性\n- **平均分數**：0.82\n\n### 模型表現比較\n\n| 模型 | 綜合得分 | 響應時間 | BERTScore | ROUGE-L |\n|------|---------|---------|-----------|---------|\n| gemma3:4b | 0.85 | 45.2s | 0.88 | 0.75 |\n| llama3-8b | 0.82 | 68.7s | 0.86 | 0.73 |\n| mistral-7b | 0.80 | 52.1s | 0.84 | 0.72 |\n\n### 最佳實踐策略排名\n\n1. **補充省略資訊** (0.92)\n   - 提升內容完整性\n   - 自動補全會議中的隱含資訊\n\n2. **明確標註發言者** (0.89)\n   - 提高可讀性\n   - 便於追蹤討論脈絡\n\n3. **結構化摘要** (0.88)\n   - 提升文件結構化程度\n   - 便於快速瀏覽重點\n\n4. **專業術語標準化** (0.86)\n   - 統一專業術語使用\n   - 提高專業性\n\n5. **標準格式模板** (0.85)\n   - 確保格式一致性\n   - 符合企業規範\n\n> **注意**：詳細評估報告請參考 [評估報告目錄](results/evaluation_reports/)\n\n## 貢獻指南\n\n我們歡迎任何形式的貢獻！以下是參與項目的步驟：\n\n1. Fork 本項目\n2. 創建特性分支 (`git checkout -b feature/amazing-feature`)\n3. 提交更改 (`git commit -m 'Add some amazing feature'`)\n4. 推送到分支 (`git push origin feature/amazing-feature`)\n5. 開啟 Pull Request\n\n### 代碼風格\n- 使用 [Black](https://github.com/psf/black) 進行代碼格式化\n- 使用 [Google 風格的 Python 文檔字符串](https://google.github.io/styleguide/pyguide.html#38-comments-and-docstrings)\n\n### 提交信息規範\n請遵循 [Conventional Commits](https://www.conventionalcommits.org/) 規範：\n- feat: 新功能\n- fix: 修復 bug\n- docs: 文檔更新\n- style: 代碼格式\n- refactor: 代碼重構\n- test: 測試相關\n- chore: 構建過程或輔助工具的變動\n\n## 專案進度\n\n### 完成情況\n\n1. **基本架構建立** ✅ 已完成\n   - 專案目錄結構\n   - 基礎優化流程\n   - 多模型支援\n\n2. **評估系統實現** ✅ 已完成\n   - ✅ 基本評估框架\n   - ✅ BERTScore 實現\n   - ✅ ROUGE 實現\n   - ✅ 多指標整合\n   - ✅ 評估報告生成\n   - ✅ 評估報告優化 (改為結構化數據格式)\n\n### 當前階段\n\n3. **提示工程優化** 🚀 進行中\n   - 大模型輔助提示詞優化\n   - 非監督學習優化循環\n   - 自動化評估與反饋\n\n### 後續計劃\n\n4. **效能優化** ⏳ 未開始\n   - 並行處理優化\n   - 快取機制實現\n   - 資源使用監控\n\n5. **系統整合** ⏳ 未開始\n   - API 服務封裝\n   - 自動化部署流程\n   - 監控告警系統\n\n## 系統需求與優化\n\n### 硬體配置\n\n- **裝置**：MacBook Pro (M4 晶片)\n- **CPU**：10 核心 (4 個效能核心 + 6 個節能核心)\n- **記憶體**：16GB 統一記憶體\n- **GPU**：Apple M4 整合式顯示晶片\n\n### 模型配置\n\n- **基礎模型**：`cwchang/llama3-taide-lx-8b-chat-alpha1:latest`\n  - 使用 4-bit 量化載入\n  - 主要用於會議記錄生成\n\n- **優化模型**：`google/gemma-3-12b`\n  - 使用 4-bit 量化載入\n  - 用於提示詞優化和改進\n\n## 提示工程優化架構\n\n### 核心組件\n\n1. **會議上下文感知模組**\n   - 自動識別會議類型和特徵\n   - 分析參與者角色和互動模式\n   - 提取關鍵決策點和行動項目\n\n2. **分層提示詞引擎**\n   - 感知層：理解會議本質特徵\n   - 策略層：選擇最優記錄策略\n   - 執行層：生成結構化會議記錄\n\n3. **動態策略管理器**\n   - 多種會議類型的專用策略\n   - 上下文感知的模板選擇\n   - 實時策略調整機制\n\n### 技術實現\n\n```python\n# 會議上下文分析示例\nclass MeetingAnalyzer:\n    def analyze(self, meeting_data: dict) -> MeetingContext:\n        context = MeetingContext()\n        context.meeting_type = self._classify_meeting_type(meeting_data)\n        context.participants = self._extract_participants(meeting_data)\n        context.decision_density = self._calculate_decision_density(meeting_data)\n        return context\n```\n\n### 實施路線圖\n\n#### 階段一：基礎架構重構 (2週)\n- [ ] 實現會議上下文感知模組\n- [ ] 開發分層提示詞引擎基礎框架\n- [ ] 創建3種基礎會議類型的適配器\n\n#### 階段二：動態策略實現 (3週)\n- [ ] 實現策略管理器\n- [ ] 開發模板組件系統\n- [ ] 整合上下文感知評估\n\n#### 階段三：自適應優化 (3週)\n- [ ] 實現強化學習優化器\n- [ ] 設置在線學習循環\n- [ ] 集成知識圖譜\n\n### 預期效益\n\n- **更智能的會議理解**：超越表面指標，理解會議本質\n- **動態適配能力**：根據會議類型自動調整記錄策略\n- **持續優化**：通過在線學習不斷改進表現\n- **更好的可解釋性**：清晰的決策過程和優化路徑\n\n### 技術棧\n\n- **核心框架**：Python 3.9+\n- **機器學習**：PyTorch, Transformers, bitsandbytes (4-bit 量化)\n- **NLP工具**：sentence-transformers, NLTK\n- **記憶體優化**：accelerate, vLLM (可選)\n- **監控工具**：psutil, GPUtil\n\n### 記憶體優化策略\n\n1. **模型量化**\n   - 使用 4-bit 量化技術\n   - 動態量化權重矩陣\n   - 啟用 Flash Attention 2 (如支援)\n\n2. **批次處理**\n   - 小批次處理輸入數據\n   - 實現記憶體監控\n   - 動態調整批次大小\n\n3. **快取機制**\n   - 使用 LRU 快取優化結果\n   - 實現提示詞模板快取\n   - 特徵向量快取\n\n4. **資源監控**\n   - 即時監控記憶體使用\n   - 動態降級機制\n   - 自動清理未使用的資源\n\n### 開發原則\n\n1. **資源效率**：優先考慮記憶體和計算效率\n2. **漸進式增強**：先實現核心功能，再逐步優化\n3. **可觀察性**：完善的監控和日誌記錄\n4. **優雅降級**：在資源受限時自動調整功能\n\n### 效能基準\n\n| 任務 | 預期記憶體使用 | 預期處理時間 |\n|------|--------------|------------|\n| 模型載入 | ~8GB | 30-60秒 |\n| 提示詞優化 | ~12GB | 5-15秒/提示 |\n| 批次處理 (n=5) | ~14GB | 20-40秒 |\n\n> **注意**：實際數值可能因系統負載和具體輸入而異\n\n### 已知限制\n\n1. **記憶體限制**：\n   - 同時載入多個大型模型可能導致記憶體不足\n   - 建議一次只載入一個模型進行推理\n\n2. **處理時間**：\n   - 複雜提示詞可能需要更長處理時間\n   - 批次處理時延遲會增加\n\n3. **建議的最佳實踐**：\n   - 實現請求佇列系統\n   - 設定處理超時機制\n   - 定期重啟長時間運行的程序以釋放記憶體\n\n## 最近更新\n\n### 2025-05-28 (最新)\n- 重構提示工程優化架構\n- 實現分層提示詞引擎\n- 新增會議上下文感知模組\n- 設計動態策略管理系統\n- 更新實施路線圖\n\n### 2025-05-27\n- 更新 README 文件，改進文檔結構和內容完整性\n- 修復評估階段文件路徑比對問題\n- 優化模型名稱處理邏輯，支援不同格式的模型名稱\n- 改進評估腳本，可選擇性評估特定模型的結果\n- 更新 `run_optimization.sh` 腳本，確保正確傳遞模型參數\n- 改進錯誤處理和日誌記錄\n- 新增模型執行時間統計功能\n- 新增策略執行時間統計功能\n- 添加 `run_all_models.sh` 腳本用於批量運行多個模型\n\n### 2025-05-27\n- 新增模型執行時間統計功能\n- 新增策略執行時間統計功能\n- 改進模型名稱處理邏輯\n- 優化錯誤處理和重試機制\n- 添加 `run_all_models.sh` 腳本用於批量運行多個模型\n\n### 2025-05-26\n- 實現模型響應時間追蹤\n- 優化模型調用過程中的錯誤處理\n- 改進重試機制，提高穩定性\n\n### 2025-05-25\n- 修復 `time` 模組導入問題\n- 修正 `model_timings` 和 `strategy_timings` 變數作用域問題\n- 更新評估結果和改進策略\n\n## 授權\n\n本項目採用 [MIT 許可證](LICENSE) 授權。"
        ]
      },
      "timestamp": "2025-05-28T14:04:30.353260"
    },
    {
      "iteration": 3,
      "stability_score": 0.6999999999999997,
      "quality_score": 0.0,
      "overall_score": 0.4199999999999998,
      "metrics": {
        "stability_score": 0.6999999999999997,
        "quality_score": 0.0,
        "overall_score": 0.4199999999999998,
        "stability_metrics": {
          "format_consistency": 0.9999999999999997,
          "length_stability": 1.0,
          "key_element_coverage": 0.0,
          "semantic_stability": 0.9999999999999992,
          "overall_stability": 0.6999999999999997
        },
        "quality_metrics": {
          "categories": {
            "semantic_similarity": {
              "name": "semantic_similarity",
              "score": 0.0,
              "metrics": {
                "bertscore_f1": {
                  "score": 0.0,
                  "weight": 1.0,
                  "details": {
                    "error": "unhashable type: 'list'"
                  }
                }
              }
            },
            "content_coverage": {
              "name": "content_coverage",
              "score": 0.0,
              "metrics": {
                "rouge1": {
                  "score": 0.0,
                  "weight": 0.3,
                  "details": {
                    "error": "'list' object has no attribute 'lower'"
                  }
                },
                "rouge2": {
                  "score": 0.0,
                  "weight": 0.4,
                  "details": {
                    "error": "'list' object has no attribute 'lower'"
                  }
                },
                "rougeL": {
                  "score": 0.0,
                  "weight": 0.3,
                  "details": {
                    "error": "'list' object has no attribute 'lower'"
                  }
                }
              }
            },
            "structure_quality": {
              "name": "structure_quality",
              "score": 0.0,
              "metrics": {
                "section_heading_quality": {
                  "score": 0.0,
                  "weight": 0.4,
                  "details": {
                    "error": "'list' object has no attribute 'split'"
                  }
                },
                "paragraph_structure": {
                  "score": 0.0,
                  "weight": 0.3,
                  "details": {
                    "error": "'list' object has no attribute 'split'"
                  }
                },
                "list_usage": {
                  "score": 0.0,
                  "weight": 0.3,
                  "details": {
                    "error": "'list' object has no attribute 'split'"
                  }
                }
              }
            }
          },
          "overall_score": 0.0
        },
        "generated_samples": [
          "生成的會議記錄（基於模板和參考文本）:\n\n\n參考:\ntorch>=2.0.0\ntransformers>=4.30.0\nevaluate>=0.4.0\nrouge-score>=0.1.2\nbert-score>=0.3.13\ntqdm>=4.65.0\npandas>=1.5.0\nnumpy>=1.24.0\nscikit-learn>=1.2.0",
          "生成的會議記錄（基於模板和參考文本）:\n\n\n參考:\ntorch>=2.0.0\ntransformers>=4.30.0\nevaluate>=0.4.0\nrouge-score>=0.1.2\nbert-score>=0.3.13\ntqdm>=4.65.0\npandas>=1.5.0\nnumpy>=1.24.0\nscikit-learn>=1.2.0",
          "生成的會議記錄（基於模板和參考文本）:\n\n\n參考:\ntorch>=2.0.0\ntransformers>=4.30.0\nevaluate>=0.4.0\nrouge-score>=0.1.2\nbert-score>=0.3.13\ntqdm>=4.65.0\npandas>=1.5.0\nnumpy>=1.24.0\nscikit-learn>=1.2.0"
        ]
      },
      "timestamp": "2025-05-28T14:04:32.434957"
    },
    {
      "iteration": 4,
      "stability_score": 0.4564134787185976,
      "quality_score": 0.0,
      "overall_score": 0.27384808723115855,
      "metrics": {
        "stability_score": 0.4564134787185976,
        "quality_score": 0.0,
        "overall_score": 0.27384808723115855,
        "stability_metrics": {
          "format_consistency": 0.7688477110772943,
          "length_stability": 0.5959339032443975,
          "key_element_coverage": 0.1111111111111111,
          "semantic_stability": 0.3661952570659825,
          "overall_stability": 0.4564134787185976
        },
        "quality_metrics": {
          "categories": {
            "semantic_similarity": {
              "name": "semantic_similarity",
              "score": 0.0,
              "metrics": {
                "bertscore_f1": {
                  "score": 0.0,
                  "weight": 1.0,
                  "details": {
                    "error": "unhashable type: 'list'"
                  }
                }
              }
            },
            "content_coverage": {
              "name": "content_coverage",
              "score": 0.0,
              "metrics": {
                "rouge1": {
                  "score": 0.0,
                  "weight": 0.3,
                  "details": {
                    "error": "'list' object has no attribute 'lower'"
                  }
                },
                "rouge2": {
                  "score": 0.0,
                  "weight": 0.4,
                  "details": {
                    "error": "'list' object has no attribute 'lower'"
                  }
                },
                "rougeL": {
                  "score": 0.0,
                  "weight": 0.3,
                  "details": {
                    "error": "'list' object has no attribute 'lower'"
                  }
                }
              }
            },
            "structure_quality": {
              "name": "structure_quality",
              "score": 0.0,
              "metrics": {
                "section_heading_quality": {
                  "score": 0.0,
                  "weight": 0.4,
                  "details": {
                    "error": "'list' object has no attribute 'split'"
                  }
                },
                "paragraph_structure": {
                  "score": 0.0,
                  "weight": 0.3,
                  "details": {
                    "error": "'list' object has no attribute 'split'"
                  }
                },
                "list_usage": {
                  "score": 0.0,
                  "weight": 0.3,
                  "details": {
                    "error": "'list' object has no attribute 'split'"
                  }
                }
              }
            }
          },
          "overall_score": 0.0
        },
        "generated_samples": [
          "生成的會議記錄（基於模板和參考文本）:\n\n\n參考:\n# 會議記錄優化與評估系統\n\n## 專案概述\n\n本專案旨在利用大型語言模型（LLM）來自動優化會議記錄，提高其結構化程度、完整性和可讀性。系統支援多種優化策略，並提供全面的評估框架來衡量優化效果。\n\n## 主要功能\n\n- **多策略優化**：支援多種會議記錄優化策略\n- **多模型支援**：可與多種開源和商業語言模型整合\n- **自動化評估**：提供多種評估指標來衡量優化效果\n- **可擴展架構**：易於添加新的優化策略和評估指標\n\n## 快速開始\n\n### 前置需求\n- Python 3.8+\n- Ollama 服務 (用於運行本地模型)\n\n### 安裝步驟\n\n```bash\n# 1. 克隆存儲庫\ngit clone https://github.com/colabbrave/exam08.git\ncd exam08\n\n# 2. 創建並啟動虛擬環境\npython -m venv venv\nsource venv/bin/activate  # Linux/Mac\n# 或\n# .\\venv\\Scripts\\activate  # Windows\n\n# 3. 安裝依賴\npip install -r requirements.txt\n\n# 4. 下載並啟動 Ollama 模型\nollama pull gemma3:4b  # 或其他支援的模型\n```\n\n### 基本用法\n\n```bash\n# 優化會議記錄\n./run_optimization.sh\n\n# 或指定模型\n./run_optimization.sh --model gemma3:4b\n\n# 評估優化結果\npython scripts/evaluate.py --model gemma3_4b\n```\n\n## 專案結構\n\n```\n.\n├── config/                  # 配置文件\n├── data/                    # 數據目錄\n│   ├── reference/           # 參考會議記錄\n│   └── transcript/          # 原始逐字稿\n├── docu/                    # 文檔\n├── logs/                    # 運行日誌\n├── models/                  # 模型文件\n├── prompts/                 # 提示詞模板\n│   ├── base/                # 基礎提示詞\n│   ├── components/          # 提示詞組件\n│   ├── optimized/           # 優化後的提示詞\n│   └── preloaded/           # 預加載的提示詞\n├── results/                 # 結果輸出\n│   ├── evaluation_reports/  # 評估報告\n│   └── optimized/           # 優化後的會議記錄\n└── scripts/                 # 腳本文件\n    ├── evaluate.py          # 評估腳本\n    ├── optimize.py          # 優化腳本\n    ├── model_manager.py     # 模型管理\n    ├── ollama_manager.py    # Ollama 集成\n    └── select_model.py      # 模型選擇\n```\n\n## 評估結果\n\n### 多指標評估系統\n\n我們實現了全面的多指標評估系統，包含以下主要指標：\n\n#### 1. 語義相似度 (權重 50%)\n- **BERTScore F1**：衡量優化前後文本的語義相似度\n- **平均分數**：0.85\n\n#### 2. 內容覆蓋度 (權重 30%)\n- **ROUGE-1**：unigram 層面的覆蓋度\n- **ROUGE-2**：bigram 層面的覆蓋度\n- **ROUGE-L**：最長公共子序列\n- **平均分數**：0.78\n\n#### 3. 結構化程度 (權重 20%)\n- 章節標題質量\n- 段落結構質量\n- 列表使用適當性\n- **平均分數**：0.82\n\n### 模型表現比較\n\n| 模型 | 綜合得分 | 響應時間 | BERTScore | ROUGE-L |\n|------|---------|---------|-----------|---------|\n| gemma3:4b | 0.85 | 45.2s | 0.88 | 0.75 |\n| llama3-8b | 0.82 | 68.7s | 0.86 | 0.73 |\n| mistral-7b | 0.80 | 52.1s | 0.84 | 0.72 |\n\n### 最佳實踐策略排名\n\n1. **補充省略資訊** (0.92)\n   - 提升內容完整性\n   - 自動補全會議中的隱含資訊\n\n2. **明確標註發言者** (0.89)\n   - 提高可讀性\n   - 便於追蹤討論脈絡\n\n3. **結構化摘要** (0.88)\n   - 提升文件結構化程度\n   - 便於快速瀏覽重點\n\n4. **專業術語標準化** (0.86)\n   - 統一專業術語使用\n   - 提高專業性\n\n5. **標準格式模板** (0.85)\n   - 確保格式一致性\n   - 符合企業規範\n\n> **注意**：詳細評估報告請參考 [評估報告目錄](results/evaluation_reports/)\n\n## 貢獻指南\n\n我們歡迎任何形式的貢獻！以下是參與項目的步驟：\n\n1. Fork 本項目\n2. 創建特性分支 (`git checkout -b feature/amazing-feature`)\n3. 提交更改 (`git commit -m 'Add some amazing feature'`)\n4. 推送到分支 (`git push origin feature/amazing-feature`)\n5. 開啟 Pull Request\n\n### 代碼風格\n- 使用 [Black](https://github.com/psf/black) 進行代碼格式化\n- 使用 [Google 風格的 Python 文檔字符串](https://google.github.io/styleguide/pyguide.html#38-comments-and-docstrings)\n\n### 提交信息規範\n請遵循 [Conventional Commits](https://www.conventionalcommits.org/) 規範：\n- feat: 新功能\n- fix: 修復 bug\n- docs: 文檔更新\n- style: 代碼格式\n- refactor: 代碼重構\n- test: 測試相關\n- chore: 構建過程或輔助工具的變動\n\n## 專案進度\n\n### 完成情況\n\n1. **基本架構建立** ✅ 已完成\n   - 專案目錄結構\n   - 基礎優化流程\n   - 多模型支援\n\n2. **評估系統實現** ✅ 已完成\n   - ✅ 基本評估框架\n   - ✅ BERTScore 實現\n   - ✅ ROUGE 實現\n   - ✅ 多指標整合\n   - ✅ 評估報告生成\n   - ✅ 評估報告優化 (改為結構化數據格式)\n\n### 當前階段\n\n3. **提示工程優化** 🚀 進行中\n   - 大模型輔助提示詞優化\n   - 非監督學習優化循環\n   - 自動化評估與反饋\n\n### 後續計劃\n\n4. **效能優化** ⏳ 未開始\n   - 並行處理優化\n   - 快取機制實現\n   - 資源使用監控\n\n5. **系統整合** ⏳ 未開始\n   - API 服務封裝\n   - 自動化部署流程\n   - 監控告警系統\n\n## 系統需求與優化\n\n### 硬體配置\n\n- **裝置**：MacBook Pro (M4 晶片)\n- **CPU**：10 核心 (4 個效能核心 + 6 個節能核心)\n- **記憶體**：16GB 統一記憶體\n- **GPU**：Apple M4 整合式顯示晶片\n\n### 模型配置\n\n- **基礎模型**：`cwchang/llama3-taide-lx-8b-chat-alpha1:latest`\n  - 使用 4-bit 量化載入\n  - 主要用於會議記錄生成\n\n- **優化模型**：`google/gemma-3-12b`\n  - 使用 4-bit 量化載入\n  - 用於提示詞優化和改進\n\n## 提示工程優化架構\n\n### 核心組件\n\n1. **會議上下文感知模組**\n   - 自動識別會議類型和特徵\n   - 分析參與者角色和互動模式\n   - 提取關鍵決策點和行動項目\n\n2. **分層提示詞引擎**\n   - 感知層：理解會議本質特徵\n   - 策略層：選擇最優記錄策略\n   - 執行層：生成結構化會議記錄\n\n3. **動態策略管理器**\n   - 多種會議類型的專用策略\n   - 上下文感知的模板選擇\n   - 實時策略調整機制\n\n### 技術實現\n\n```python\n# 會議上下文分析示例\nclass MeetingAnalyzer:\n    def analyze(self, meeting_data: dict) -> MeetingContext:\n        context = MeetingContext()\n        context.meeting_type = self._classify_meeting_type(meeting_data)\n        context.participants = self._extract_participants(meeting_data)\n        context.decision_density = self._calculate_decision_density(meeting_data)\n        return context\n```\n\n### 實施路線圖\n\n#### 階段一：基礎架構重構 (2週)\n- [ ] 實現會議上下文感知模組\n- [ ] 開發分層提示詞引擎基礎框架\n- [ ] 創建3種基礎會議類型的適配器\n\n#### 階段二：動態策略實現 (3週)\n- [ ] 實現策略管理器\n- [ ] 開發模板組件系統\n- [ ] 整合上下文感知評估\n\n#### 階段三：自適應優化 (3週)\n- [ ] 實現強化學習優化器\n- [ ] 設置在線學習循環\n- [ ] 集成知識圖譜\n\n### 預期效益\n\n- **更智能的會議理解**：超越表面指標，理解會議本質\n- **動態適配能力**：根據會議類型自動調整記錄策略\n- **持續優化**：通過在線學習不斷改進表現\n- **更好的可解釋性**：清晰的決策過程和優化路徑\n\n### 技術棧\n\n- **核心框架**：Python 3.9+\n- **機器學習**：PyTorch, Transformers, bitsandbytes (4-bit 量化)\n- **NLP工具**：sentence-transformers, NLTK\n- **記憶體優化**：accelerate, vLLM (可選)\n- **監控工具**：psutil, GPUtil\n\n### 記憶體優化策略\n\n1. **模型量化**\n   - 使用 4-bit 量化技術\n   - 動態量化權重矩陣\n   - 啟用 Flash Attention 2 (如支援)\n\n2. **批次處理**\n   - 小批次處理輸入數據\n   - 實現記憶體監控\n   - 動態調整批次大小\n\n3. **快取機制**\n   - 使用 LRU 快取優化結果\n   - 實現提示詞模板快取\n   - 特徵向量快取\n\n4. **資源監控**\n   - 即時監控記憶體使用\n   - 動態降級機制\n   - 自動清理未使用的資源\n\n### 開發原則\n\n1. **資源效率**：優先考慮記憶體和計算效率\n2. **漸進式增強**：先實現核心功能，再逐步優化\n3. **可觀察性**：完善的監控和日誌記錄\n4. **優雅降級**：在資源受限時自動調整功能\n\n### 效能基準\n\n| 任務 | 預期記憶體使用 | 預期處理時間 |\n|------|--------------|------------|\n| 模型載入 | ~8GB | 30-60秒 |\n| 提示詞優化 | ~12GB | 5-15秒/提示 |\n| 批次處理 (n=5) | ~14GB | 20-40秒 |\n\n> **注意**：實際數值可能因系統負載和具體輸入而異\n\n### 已知限制\n\n1. **記憶體限制**：\n   - 同時載入多個大型模型可能導致記憶體不足\n   - 建議一次只載入一個模型進行推理\n\n2. **處理時間**：\n   - 複雜提示詞可能需要更長處理時間\n   - 批次處理時延遲會增加\n\n3. **建議的最佳實踐**：\n   - 實現請求佇列系統\n   - 設定處理超時機制\n   - 定期重啟長時間運行的程序以釋放記憶體\n\n## 最近更新\n\n### 2025-05-28 (最新)\n- 重構提示工程優化架構\n- 實現分層提示詞引擎\n- 新增會議上下文感知模組\n- 設計動態策略管理系統\n- 更新實施路線圖\n\n### 2025-05-27\n- 更新 README 文件，改進文檔結構和內容完整性\n- 修復評估階段文件路徑比對問題\n- 優化模型名稱處理邏輯，支援不同格式的模型名稱\n- 改進評估腳本，可選擇性評估特定模型的結果\n- 更新 `run_optimization.sh` 腳本，確保正確傳遞模型參數\n- 改進錯誤處理和日誌記錄\n- 新增模型執行時間統計功能\n- 新增策略執行時間統計功能\n- 添加 `run_all_models.sh` 腳本用於批量運行多個模型\n\n### 2025-05-27\n- 新增模型執行時間統計功能\n- 新增策略執行時間統計功能\n- 改進模型名稱處理邏輯\n- 優化錯誤處理和重試機制\n- 添加 `run_all_models.sh` 腳本用於批量運行多個模型\n\n### 2025-05-26\n- 實現模型響應時間追蹤\n- 優化模型調用過程中的錯誤處理\n- 改進重試機制，提高穩定性\n\n### 2025-05-25\n- 修復 `time` 模組導入問題\n- 修正 `model_timings` 和 `strategy_timings` 變數作用域問題\n- 更新評估結果和改進策略\n\n## 授權\n\n本項目採用 [MIT 許可證](LICENSE) 授權。",
          "生成的會議記錄（基於模板和參考文本）:\n\n\n參考:\ntorch>=2.0.0\ntransformers>=4.30.0\nevaluate>=0.4.0\nrouge-score>=0.1.2\nbert-score>=0.3.13\ntqdm>=4.65.0\npandas>=1.5.0\nnumpy>=1.24.0\nscikit-learn>=1.2.0",
          "生成的會議記錄（基於模板和參考文本）:\n\n\n參考:\n# 會議記錄優化與評估系統\n\n## 專案概述\n\n本專案旨在利用大型語言模型（LLM）來自動優化會議記錄，提高其結構化程度、完整性和可讀性。系統支援多種優化策略，並提供全面的評估框架來衡量優化效果。\n\n## 主要功能\n\n- **多策略優化**：支援多種會議記錄優化策略\n- **多模型支援**：可與多種開源和商業語言模型整合\n- **自動化評估**：提供多種評估指標來衡量優化效果\n- **可擴展架構**：易於添加新的優化策略和評估指標\n\n## 快速開始\n\n### 前置需求\n- Python 3.8+\n- Ollama 服務 (用於運行本地模型)\n\n### 安裝步驟\n\n```bash\n# 1. 克隆存儲庫\ngit clone https://github.com/colabbrave/exam08.git\ncd exam08\n\n# 2. 創建並啟動虛擬環境\npython -m venv venv\nsource venv/bin/activate  # Linux/Mac\n# 或\n# .\\venv\\Scripts\\activate  # Windows\n\n# 3. 安裝依賴\npip install -r requirements.txt\n\n# 4. 下載並啟動 Ollama 模型\nollama pull gemma3:4b  # 或其他支援的模型\n```\n\n### 基本用法\n\n```bash\n# 優化會議記錄\n./run_optimization.sh\n\n# 或指定模型\n./run_optimization.sh --model gemma3:4b\n\n# 評估優化結果\npython scripts/evaluate.py --model gemma3_4b\n```\n\n## 專案結構\n\n```\n.\n├── config/                  # 配置文件\n├── data/                    # 數據目錄\n│   ├── reference/           # 參考會議記錄\n│   └── transcript/          # 原始逐字稿\n├── docu/                    # 文檔\n├── logs/                    # 運行日誌\n├── models/                  # 模型文件\n├── prompts/                 # 提示詞模板\n│   ├── base/                # 基礎提示詞\n│   ├── components/          # 提示詞組件\n│   ├── optimized/           # 優化後的提示詞\n│   └── preloaded/           # 預加載的提示詞\n├── results/                 # 結果輸出\n│   ├── evaluation_reports/  # 評估報告\n│   └── optimized/           # 優化後的會議記錄\n└── scripts/                 # 腳本文件\n    ├── evaluate.py          # 評估腳本\n    ├── optimize.py          # 優化腳本\n    ├── model_manager.py     # 模型管理\n    ├── ollama_manager.py    # Ollama 集成\n    └── select_model.py      # 模型選擇\n```\n\n## 評估結果\n\n### 多指標評估系統\n\n我們實現了全面的多指標評估系統，包含以下主要指標：\n\n#### 1. 語義相似度 (權重 50%)\n- **BERTScore F1**：衡量優化前後文本的語義相似度\n- **平均分數**：0.85\n\n#### 2. 內容覆蓋度 (權重 30%)\n- **ROUGE-1**：unigram 層面的覆蓋度\n- **ROUGE-2**：bigram 層面的覆蓋度\n- **ROUGE-L**：最長公共子序列\n- **平均分數**：0.78\n\n#### 3. 結構化程度 (權重 20%)\n- 章節標題質量\n- 段落結構質量\n- 列表使用適當性\n- **平均分數**：0.82\n\n### 模型表現比較\n\n| 模型 | 綜合得分 | 響應時間 | BERTScore | ROUGE-L |\n|------|---------|---------|-----------|---------|\n| gemma3:4b | 0.85 | 45.2s | 0.88 | 0.75 |\n| llama3-8b | 0.82 | 68.7s | 0.86 | 0.73 |\n| mistral-7b | 0.80 | 52.1s | 0.84 | 0.72 |\n\n### 最佳實踐策略排名\n\n1. **補充省略資訊** (0.92)\n   - 提升內容完整性\n   - 自動補全會議中的隱含資訊\n\n2. **明確標註發言者** (0.89)\n   - 提高可讀性\n   - 便於追蹤討論脈絡\n\n3. **結構化摘要** (0.88)\n   - 提升文件結構化程度\n   - 便於快速瀏覽重點\n\n4. **專業術語標準化** (0.86)\n   - 統一專業術語使用\n   - 提高專業性\n\n5. **標準格式模板** (0.85)\n   - 確保格式一致性\n   - 符合企業規範\n\n> **注意**：詳細評估報告請參考 [評估報告目錄](results/evaluation_reports/)\n\n## 貢獻指南\n\n我們歡迎任何形式的貢獻！以下是參與項目的步驟：\n\n1. Fork 本項目\n2. 創建特性分支 (`git checkout -b feature/amazing-feature`)\n3. 提交更改 (`git commit -m 'Add some amazing feature'`)\n4. 推送到分支 (`git push origin feature/amazing-feature`)\n5. 開啟 Pull Request\n\n### 代碼風格\n- 使用 [Black](https://github.com/psf/black) 進行代碼格式化\n- 使用 [Google 風格的 Python 文檔字符串](https://google.github.io/styleguide/pyguide.html#38-comments-and-docstrings)\n\n### 提交信息規範\n請遵循 [Conventional Commits](https://www.conventionalcommits.org/) 規範：\n- feat: 新功能\n- fix: 修復 bug\n- docs: 文檔更新\n- style: 代碼格式\n- refactor: 代碼重構\n- test: 測試相關\n- chore: 構建過程或輔助工具的變動\n\n## 專案進度\n\n### 完成情況\n\n1. **基本架構建立** ✅ 已完成\n   - 專案目錄結構\n   - 基礎優化流程\n   - 多模型支援\n\n2. **評估系統實現** ✅ 已完成\n   - ✅ 基本評估框架\n   - ✅ BERTScore 實現\n   - ✅ ROUGE 實現\n   - ✅ 多指標整合\n   - ✅ 評估報告生成\n   - ✅ 評估報告優化 (改為結構化數據格式)\n\n### 當前階段\n\n3. **提示工程優化** 🚀 進行中\n   - 大模型輔助提示詞優化\n   - 非監督學習優化循環\n   - 自動化評估與反饋\n\n### 後續計劃\n\n4. **效能優化** ⏳ 未開始\n   - 並行處理優化\n   - 快取機制實現\n   - 資源使用監控\n\n5. **系統整合** ⏳ 未開始\n   - API 服務封裝\n   - 自動化部署流程\n   - 監控告警系統\n\n## 系統需求與優化\n\n### 硬體配置\n\n- **裝置**：MacBook Pro (M4 晶片)\n- **CPU**：10 核心 (4 個效能核心 + 6 個節能核心)\n- **記憶體**：16GB 統一記憶體\n- **GPU**：Apple M4 整合式顯示晶片\n\n### 模型配置\n\n- **基礎模型**：`cwchang/llama3-taide-lx-8b-chat-alpha1:latest`\n  - 使用 4-bit 量化載入\n  - 主要用於會議記錄生成\n\n- **優化模型**：`google/gemma-3-12b`\n  - 使用 4-bit 量化載入\n  - 用於提示詞優化和改進\n\n## 提示工程優化架構\n\n### 核心組件\n\n1. **會議上下文感知模組**\n   - 自動識別會議類型和特徵\n   - 分析參與者角色和互動模式\n   - 提取關鍵決策點和行動項目\n\n2. **分層提示詞引擎**\n   - 感知層：理解會議本質特徵\n   - 策略層：選擇最優記錄策略\n   - 執行層：生成結構化會議記錄\n\n3. **動態策略管理器**\n   - 多種會議類型的專用策略\n   - 上下文感知的模板選擇\n   - 實時策略調整機制\n\n### 技術實現\n\n```python\n# 會議上下文分析示例\nclass MeetingAnalyzer:\n    def analyze(self, meeting_data: dict) -> MeetingContext:\n        context = MeetingContext()\n        context.meeting_type = self._classify_meeting_type(meeting_data)\n        context.participants = self._extract_participants(meeting_data)\n        context.decision_density = self._calculate_decision_density(meeting_data)\n        return context\n```\n\n### 實施路線圖\n\n#### 階段一：基礎架構重構 (2週)\n- [ ] 實現會議上下文感知模組\n- [ ] 開發分層提示詞引擎基礎框架\n- [ ] 創建3種基礎會議類型的適配器\n\n#### 階段二：動態策略實現 (3週)\n- [ ] 實現策略管理器\n- [ ] 開發模板組件系統\n- [ ] 整合上下文感知評估\n\n#### 階段三：自適應優化 (3週)\n- [ ] 實現強化學習優化器\n- [ ] 設置在線學習循環\n- [ ] 集成知識圖譜\n\n### 預期效益\n\n- **更智能的會議理解**：超越表面指標，理解會議本質\n- **動態適配能力**：根據會議類型自動調整記錄策略\n- **持續優化**：通過在線學習不斷改進表現\n- **更好的可解釋性**：清晰的決策過程和優化路徑\n\n### 技術棧\n\n- **核心框架**：Python 3.9+\n- **機器學習**：PyTorch, Transformers, bitsandbytes (4-bit 量化)\n- **NLP工具**：sentence-transformers, NLTK\n- **記憶體優化**：accelerate, vLLM (可選)\n- **監控工具**：psutil, GPUtil\n\n### 記憶體優化策略\n\n1. **模型量化**\n   - 使用 4-bit 量化技術\n   - 動態量化權重矩陣\n   - 啟用 Flash Attention 2 (如支援)\n\n2. **批次處理**\n   - 小批次處理輸入數據\n   - 實現記憶體監控\n   - 動態調整批次大小\n\n3. **快取機制**\n   - 使用 LRU 快取優化結果\n   - 實現提示詞模板快取\n   - 特徵向量快取\n\n4. **資源監控**\n   - 即時監控記憶體使用\n   - 動態降級機制\n   - 自動清理未使用的資源\n\n### 開發原則\n\n1. **資源效率**：優先考慮記憶體和計算效率\n2. **漸進式增強**：先實現核心功能，再逐步優化\n3. **可觀察性**：完善的監控和日誌記錄\n4. **優雅降級**：在資源受限時自動調整功能\n\n### 效能基準\n\n| 任務 | 預期記憶體使用 | 預期處理時間 |\n|------|--------------|------------|\n| 模型載入 | ~8GB | 30-60秒 |\n| 提示詞優化 | ~12GB | 5-15秒/提示 |\n| 批次處理 (n=5) | ~14GB | 20-40秒 |\n\n> **注意**：實際數值可能因系統負載和具體輸入而異\n\n### 已知限制\n\n1. **記憶體限制**：\n   - 同時載入多個大型模型可能導致記憶體不足\n   - 建議一次只載入一個模型進行推理\n\n2. **處理時間**：\n   - 複雜提示詞可能需要更長處理時間\n   - 批次處理時延遲會增加\n\n3. **建議的最佳實踐**：\n   - 實現請求佇列系統\n   - 設定處理超時機制\n   - 定期重啟長時間運行的程序以釋放記憶體\n\n## 最近更新\n\n### 2025-05-28 (最新)\n- 重構提示工程優化架構\n- 實現分層提示詞引擎\n- 新增會議上下文感知模組\n- 設計動態策略管理系統\n- 更新實施路線圖\n\n### 2025-05-27\n- 更新 README 文件，改進文檔結構和內容完整性\n- 修復評估階段文件路徑比對問題\n- 優化模型名稱處理邏輯，支援不同格式的模型名稱\n- 改進評估腳本，可選擇性評估特定模型的結果\n- 更新 `run_optimization.sh` 腳本，確保正確傳遞模型參數\n- 改進錯誤處理和日誌記錄\n- 新增模型執行時間統計功能\n- 新增策略執行時間統計功能\n- 添加 `run_all_models.sh` 腳本用於批量運行多個模型\n\n### 2025-05-27\n- 新增模型執行時間統計功能\n- 新增策略執行時間統計功能\n- 改進模型名稱處理邏輯\n- 優化錯誤處理和重試機制\n- 添加 `run_all_models.sh` 腳本用於批量運行多個模型\n\n### 2025-05-26\n- 實現模型響應時間追蹤\n- 優化模型調用過程中的錯誤處理\n- 改進重試機制，提高穩定性\n\n### 2025-05-25\n- 修復 `time` 模組導入問題\n- 修正 `model_timings` 和 `strategy_timings` 變數作用域問題\n- 更新評估結果和改進策略\n\n## 授權\n\n本項目採用 [MIT 許可證](LICENSE) 授權。"
        ]
      },
      "timestamp": "2025-05-28T14:04:34.623112"
    },
    {
      "iteration": 5,
      "stability_score": 0.4458310507463698,
      "quality_score": 0.0,
      "overall_score": 0.26749863044782185,
      "metrics": {
        "stability_score": 0.4458310507463698,
        "quality_score": 0.0,
        "overall_score": 0.26749863044782185,
        "stability_metrics": {
          "format_consistency": 0.84061086322194,
          "length_stability": 0.6217711923412099,
          "key_element_coverage": 0.0,
          "semantic_stability": 0.3464677665577291,
          "overall_stability": 0.4458310507463698
        },
        "quality_metrics": {
          "categories": {
            "semantic_similarity": {
              "name": "semantic_similarity",
              "score": 0.0,
              "metrics": {
                "bertscore_f1": {
                  "score": 0.0,
                  "weight": 1.0,
                  "details": {
                    "error": "unhashable type: 'list'"
                  }
                }
              }
            },
            "content_coverage": {
              "name": "content_coverage",
              "score": 0.0,
              "metrics": {
                "rouge1": {
                  "score": 0.0,
                  "weight": 0.3,
                  "details": {
                    "error": "'list' object has no attribute 'lower'"
                  }
                },
                "rouge2": {
                  "score": 0.0,
                  "weight": 0.4,
                  "details": {
                    "error": "'list' object has no attribute 'lower'"
                  }
                },
                "rougeL": {
                  "score": 0.0,
                  "weight": 0.3,
                  "details": {
                    "error": "'list' object has no attribute 'lower'"
                  }
                }
              }
            },
            "structure_quality": {
              "name": "structure_quality",
              "score": 0.0,
              "metrics": {
                "section_heading_quality": {
                  "score": 0.0,
                  "weight": 0.4,
                  "details": {
                    "error": "'list' object has no attribute 'split'"
                  }
                },
                "paragraph_structure": {
                  "score": 0.0,
                  "weight": 0.3,
                  "details": {
                    "error": "'list' object has no attribute 'split'"
                  }
                },
                "list_usage": {
                  "score": 0.0,
                  "weight": 0.3,
                  "details": {
                    "error": "'list' object has no attribute 'split'"
                  }
                }
              }
            }
          },
          "overall_score": 0.0
        },
        "generated_samples": [
          "生成的會議記錄（基於模板和參考文本）:\n\n\n參考:\n# 會議記錄優化工具安裝與使用指南\n\n## 環境要求\n\n- Python 3.8 或更高版本\n- CUDA 11.7 或更高版本（如需 GPU 加速）\n- 至少 16GB 系統記憶體（建議 32GB 或更多）\n- 至少 20GB 可用磁碟空間（用於模型快取）\n\n## 安裝步驟\n\n1. 克隆代碼庫：\n   ```bash\n   git clone <repository-url>\n   cd exam08_提示詞練習重啟\n   ```\n\n2. 創建並啟動虛擬環境（建議）：\n   ```bash\n   python -m venv venv\n   source venv/bin/activate  # Linux/Mac\n   # 或\n   .\\venv\\Scripts\\activate  # Windows\n   ```\n\n3. 安裝依賴：\n   ```bash\n   pip install -r requirements.txt\n   ```\n\n4. 安裝 PyTorch（如需 GPU 支援）：\n   ```bash\n   # 請根據您的 CUDA 版本選擇合適的安裝命令\n   # 例如，CUDA 11.8：\n   pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n   ```\n\n## 下載模型\n\n本工具支援多種語言模型，預設使用 `cwchang/llama3-taide-lx-8b-chat-alpha1_latest`。\n\n首次運行時，工具會自動下載模型（約 15GB）。確保您有足夠的磁碟空間和穩定的網路連接。\n\n## 使用方法\n\n### 1. 優化單個會議記錄\n\n```bash\npython scripts/optimize_meeting_minutes.py path/to/your/meeting.txt\n```\n\n### 2. 批量處理多個會議記錄\n\n```bash\n# 創建輸出目錄\nmkdir -p optimized_meetings\n\n# 處理目錄中的所有 .txt 文件\nfor f in data/meetings/*.txt; do\n    python scripts/optimize_meeting_minutes.py \"$f\" -o optimized_meetings\ndone\n```\n\n### 3. 評估優化效果\n\n```bash\n# 評估單個優化結果\npython scripts/test_optimization.py --test-dir path/to/test/files --output-dir results/evaluation\n\n# 查看評估報告\ncat results/evaluation/optimization_evaluation.json\n```\n\n## 進階選項\n\n### 使用不同的模型\n\n```bash\npython scripts/optimize_meeting_minutes.py meeting.txt --model \"jcai/llama3-taide-lx-8b-chat-alpha1_Q4_K_M\"\n```\n\n### 調整生成長度\n\n```bash\n# 增加生成長度限制\npython scripts/optimize_meeting_minutes.py meeting.txt --max-length 4096\n```\n\n## 疑難排解\n\n### 記憶體不足\n\n如果遇到記憶體不足錯誤，請嘗試：\n\n1. 減少生成長度 (`--max-length`)\n2. 使用較小的模型\n3. 增加系統交換空間\n4. 使用 CPU 模式（不推薦，速度較慢）\n\n### 模型下載問題\n\n如果模型下載失敗：\n\n1. 檢查網路連接\n2. 確保有足夠的磁碟空間\n3. 手動下載模型並指定本地路徑\n\n## 貢獻指南\n\n歡迎提交問題和拉取請求！請確保：\n\n1. 遵循現有的代碼風格\n2. 為新功能添加測試\n3. 更新相關文檔\n\n## 授權\n\n[在此添加授權信息]",
          "生成的會議記錄（基於模板和參考文本）:\n\n\n參考:\ntorch>=2.0.0\ntransformers>=4.30.0\nevaluate>=0.4.0\nrouge-score>=0.1.2\nbert-score>=0.3.13\ntqdm>=4.65.0\npandas>=1.5.0\nnumpy>=1.24.0\nscikit-learn>=1.2.0",
          "生成的會議記錄（基於模板和參考文本）:\n\n\n參考:\n# 會議記錄優化工具安裝與使用指南\n\n## 環境要求\n\n- Python 3.8 或更高版本\n- CUDA 11.7 或更高版本（如需 GPU 加速）\n- 至少 16GB 系統記憶體（建議 32GB 或更多）\n- 至少 20GB 可用磁碟空間（用於模型快取）\n\n## 安裝步驟\n\n1. 克隆代碼庫：\n   ```bash\n   git clone <repository-url>\n   cd exam08_提示詞練習重啟\n   ```\n\n2. 創建並啟動虛擬環境（建議）：\n   ```bash\n   python -m venv venv\n   source venv/bin/activate  # Linux/Mac\n   # 或\n   .\\venv\\Scripts\\activate  # Windows\n   ```\n\n3. 安裝依賴：\n   ```bash\n   pip install -r requirements.txt\n   ```\n\n4. 安裝 PyTorch（如需 GPU 支援）：\n   ```bash\n   # 請根據您的 CUDA 版本選擇合適的安裝命令\n   # 例如，CUDA 11.8：\n   pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n   ```\n\n## 下載模型\n\n本工具支援多種語言模型，預設使用 `cwchang/llama3-taide-lx-8b-chat-alpha1_latest`。\n\n首次運行時，工具會自動下載模型（約 15GB）。確保您有足夠的磁碟空間和穩定的網路連接。\n\n## 使用方法\n\n### 1. 優化單個會議記錄\n\n```bash\npython scripts/optimize_meeting_minutes.py path/to/your/meeting.txt\n```\n\n### 2. 批量處理多個會議記錄\n\n```bash\n# 創建輸出目錄\nmkdir -p optimized_meetings\n\n# 處理目錄中的所有 .txt 文件\nfor f in data/meetings/*.txt; do\n    python scripts/optimize_meeting_minutes.py \"$f\" -o optimized_meetings\ndone\n```\n\n### 3. 評估優化效果\n\n```bash\n# 評估單個優化結果\npython scripts/test_optimization.py --test-dir path/to/test/files --output-dir results/evaluation\n\n# 查看評估報告\ncat results/evaluation/optimization_evaluation.json\n```\n\n## 進階選項\n\n### 使用不同的模型\n\n```bash\npython scripts/optimize_meeting_minutes.py meeting.txt --model \"jcai/llama3-taide-lx-8b-chat-alpha1_Q4_K_M\"\n```\n\n### 調整生成長度\n\n```bash\n# 增加生成長度限制\npython scripts/optimize_meeting_minutes.py meeting.txt --max-length 4096\n```\n\n## 疑難排解\n\n### 記憶體不足\n\n如果遇到記憶體不足錯誤，請嘗試：\n\n1. 減少生成長度 (`--max-length`)\n2. 使用較小的模型\n3. 增加系統交換空間\n4. 使用 CPU 模式（不推薦，速度較慢）\n\n### 模型下載問題\n\n如果模型下載失敗：\n\n1. 檢查網路連接\n2. 確保有足夠的磁碟空間\n3. 手動下載模型並指定本地路徑\n\n## 貢獻指南\n\n歡迎提交問題和拉取請求！請確保：\n\n1. 遵循現有的代碼風格\n2. 為新功能添加測試\n3. 更新相關文檔\n\n## 授權\n\n[在此添加授權信息]"
        ]
      },
      "timestamp": "2025-05-28T14:04:36.884987"
    },
    {
      "iteration": 6,
      "stability_score": 0.3790233568799884,
      "quality_score": 0.0,
      "overall_score": 0.22741401412799303,
      "metrics": {
        "stability_score": 0.3790233568799884,
        "quality_score": 0.0,
        "overall_score": 0.22741401412799303,
        "stability_metrics": {
          "format_consistency": 0.8008431220369706,
          "length_stability": 0.5153264956137354,
          "key_element_coverage": 0.05555555555555555,
          "semantic_stability": 0.0951922723974174,
          "overall_stability": 0.3790233568799884
        },
        "quality_metrics": {
          "categories": {
            "semantic_similarity": {
              "name": "semantic_similarity",
              "score": 0.0,
              "metrics": {
                "bertscore_f1": {
                  "score": 0.0,
                  "weight": 1.0,
                  "details": {
                    "error": "unhashable type: 'list'"
                  }
                }
              }
            },
            "content_coverage": {
              "name": "content_coverage",
              "score": 0.0,
              "metrics": {
                "rouge1": {
                  "score": 0.0,
                  "weight": 0.3,
                  "details": {
                    "error": "'list' object has no attribute 'lower'"
                  }
                },
                "rouge2": {
                  "score": 0.0,
                  "weight": 0.4,
                  "details": {
                    "error": "'list' object has no attribute 'lower'"
                  }
                },
                "rougeL": {
                  "score": 0.0,
                  "weight": 0.3,
                  "details": {
                    "error": "'list' object has no attribute 'lower'"
                  }
                }
              }
            },
            "structure_quality": {
              "name": "structure_quality",
              "score": 0.0,
              "metrics": {
                "section_heading_quality": {
                  "score": 0.0,
                  "weight": 0.4,
                  "details": {
                    "error": "'list' object has no attribute 'split'"
                  }
                },
                "paragraph_structure": {
                  "score": 0.0,
                  "weight": 0.3,
                  "details": {
                    "error": "'list' object has no attribute 'split'"
                  }
                },
                "list_usage": {
                  "score": 0.0,
                  "weight": 0.3,
                  "details": {
                    "error": "'list' object has no attribute 'split'"
                  }
                }
              }
            }
          },
          "overall_score": 0.0
        },
        "generated_samples": [
          "生成的會議記錄（基於模板和參考文本）:\n\n\n參考:\ntorch>=2.0.0\ntransformers>=4.30.0\nevaluate>=0.4.0\nrouge-score>=0.1.2\nbert-score>=0.3.13\ntqdm>=4.65.0\npandas>=1.5.0\nnumpy>=1.24.0\nscikit-learn>=1.2.0",
          "生成的會議記錄（基於模板和參考文本）:\n\n\n參考:\n# 會議記錄優化與評估系統\n\n## 專案概述\n\n本專案旨在利用大型語言模型（LLM）來自動優化會議記錄，提高其結構化程度、完整性和可讀性。系統支援多種優化策略，並提供全面的評估框架來衡量優化效果。\n\n## 主要功能\n\n- **多策略優化**：支援多種會議記錄優化策略\n- **多模型支援**：可與多種開源和商業語言模型整合\n- **自動化評估**：提供多種評估指標來衡量優化效果\n- **可擴展架構**：易於添加新的優化策略和評估指標\n\n## 快速開始\n\n### 前置需求\n- Python 3.8+\n- Ollama 服務 (用於運行本地模型)\n\n### 安裝步驟\n\n```bash\n# 1. 克隆存儲庫\ngit clone https://github.com/colabbrave/exam08.git\ncd exam08\n\n# 2. 創建並啟動虛擬環境\npython -m venv venv\nsource venv/bin/activate  # Linux/Mac\n# 或\n# .\\venv\\Scripts\\activate  # Windows\n\n# 3. 安裝依賴\npip install -r requirements.txt\n\n# 4. 下載並啟動 Ollama 模型\nollama pull gemma3:4b  # 或其他支援的模型\n```\n\n### 基本用法\n\n```bash\n# 優化會議記錄\n./run_optimization.sh\n\n# 或指定模型\n./run_optimization.sh --model gemma3:4b\n\n# 評估優化結果\npython scripts/evaluate.py --model gemma3_4b\n```\n\n## 專案結構\n\n```\n.\n├── config/                  # 配置文件\n├── data/                    # 數據目錄\n│   ├── reference/           # 參考會議記錄\n│   └── transcript/          # 原始逐字稿\n├── docu/                    # 文檔\n├── logs/                    # 運行日誌\n├── models/                  # 模型文件\n├── prompts/                 # 提示詞模板\n│   ├── base/                # 基礎提示詞\n│   ├── components/          # 提示詞組件\n│   ├── optimized/           # 優化後的提示詞\n│   └── preloaded/           # 預加載的提示詞\n├── results/                 # 結果輸出\n│   ├── evaluation_reports/  # 評估報告\n│   └── optimized/           # 優化後的會議記錄\n└── scripts/                 # 腳本文件\n    ├── evaluate.py          # 評估腳本\n    ├── optimize.py          # 優化腳本\n    ├── model_manager.py     # 模型管理\n    ├── ollama_manager.py    # Ollama 集成\n    └── select_model.py      # 模型選擇\n```\n\n## 評估結果\n\n### 多指標評估系統\n\n我們實現了全面的多指標評估系統，包含以下主要指標：\n\n#### 1. 語義相似度 (權重 50%)\n- **BERTScore F1**：衡量優化前後文本的語義相似度\n- **平均分數**：0.85\n\n#### 2. 內容覆蓋度 (權重 30%)\n- **ROUGE-1**：unigram 層面的覆蓋度\n- **ROUGE-2**：bigram 層面的覆蓋度\n- **ROUGE-L**：最長公共子序列\n- **平均分數**：0.78\n\n#### 3. 結構化程度 (權重 20%)\n- 章節標題質量\n- 段落結構質量\n- 列表使用適當性\n- **平均分數**：0.82\n\n### 模型表現比較\n\n| 模型 | 綜合得分 | 響應時間 | BERTScore | ROUGE-L |\n|------|---------|---------|-----------|---------|\n| gemma3:4b | 0.85 | 45.2s | 0.88 | 0.75 |\n| llama3-8b | 0.82 | 68.7s | 0.86 | 0.73 |\n| mistral-7b | 0.80 | 52.1s | 0.84 | 0.72 |\n\n### 最佳實踐策略排名\n\n1. **補充省略資訊** (0.92)\n   - 提升內容完整性\n   - 自動補全會議中的隱含資訊\n\n2. **明確標註發言者** (0.89)\n   - 提高可讀性\n   - 便於追蹤討論脈絡\n\n3. **結構化摘要** (0.88)\n   - 提升文件結構化程度\n   - 便於快速瀏覽重點\n\n4. **專業術語標準化** (0.86)\n   - 統一專業術語使用\n   - 提高專業性\n\n5. **標準格式模板** (0.85)\n   - 確保格式一致性\n   - 符合企業規範\n\n> **注意**：詳細評估報告請參考 [評估報告目錄](results/evaluation_reports/)\n\n## 貢獻指南\n\n我們歡迎任何形式的貢獻！以下是參與項目的步驟：\n\n1. Fork 本項目\n2. 創建特性分支 (`git checkout -b feature/amazing-feature`)\n3. 提交更改 (`git commit -m 'Add some amazing feature'`)\n4. 推送到分支 (`git push origin feature/amazing-feature`)\n5. 開啟 Pull Request\n\n### 代碼風格\n- 使用 [Black](https://github.com/psf/black) 進行代碼格式化\n- 使用 [Google 風格的 Python 文檔字符串](https://google.github.io/styleguide/pyguide.html#38-comments-and-docstrings)\n\n### 提交信息規範\n請遵循 [Conventional Commits](https://www.conventionalcommits.org/) 規範：\n- feat: 新功能\n- fix: 修復 bug\n- docs: 文檔更新\n- style: 代碼格式\n- refactor: 代碼重構\n- test: 測試相關\n- chore: 構建過程或輔助工具的變動\n\n## 專案進度\n\n### 完成情況\n\n1. **基本架構建立** ✅ 已完成\n   - 專案目錄結構\n   - 基礎優化流程\n   - 多模型支援\n\n2. **評估系統實現** ✅ 已完成\n   - ✅ 基本評估框架\n   - ✅ BERTScore 實現\n   - ✅ ROUGE 實現\n   - ✅ 多指標整合\n   - ✅ 評估報告生成\n   - ✅ 評估報告優化 (改為結構化數據格式)\n\n### 當前階段\n\n3. **提示工程優化** 🚀 進行中\n   - 大模型輔助提示詞優化\n   - 非監督學習優化循環\n   - 自動化評估與反饋\n\n### 後續計劃\n\n4. **效能優化** ⏳ 未開始\n   - 並行處理優化\n   - 快取機制實現\n   - 資源使用監控\n\n5. **系統整合** ⏳ 未開始\n   - API 服務封裝\n   - 自動化部署流程\n   - 監控告警系統\n\n## 系統需求與優化\n\n### 硬體配置\n\n- **裝置**：MacBook Pro (M4 晶片)\n- **CPU**：10 核心 (4 個效能核心 + 6 個節能核心)\n- **記憶體**：16GB 統一記憶體\n- **GPU**：Apple M4 整合式顯示晶片\n\n### 模型配置\n\n- **基礎模型**：`cwchang/llama3-taide-lx-8b-chat-alpha1:latest`\n  - 使用 4-bit 量化載入\n  - 主要用於會議記錄生成\n\n- **優化模型**：`google/gemma-3-12b`\n  - 使用 4-bit 量化載入\n  - 用於提示詞優化和改進\n\n## 提示工程優化架構\n\n### 核心組件\n\n1. **會議上下文感知模組**\n   - 自動識別會議類型和特徵\n   - 分析參與者角色和互動模式\n   - 提取關鍵決策點和行動項目\n\n2. **分層提示詞引擎**\n   - 感知層：理解會議本質特徵\n   - 策略層：選擇最優記錄策略\n   - 執行層：生成結構化會議記錄\n\n3. **動態策略管理器**\n   - 多種會議類型的專用策略\n   - 上下文感知的模板選擇\n   - 實時策略調整機制\n\n### 技術實現\n\n```python\n# 會議上下文分析示例\nclass MeetingAnalyzer:\n    def analyze(self, meeting_data: dict) -> MeetingContext:\n        context = MeetingContext()\n        context.meeting_type = self._classify_meeting_type(meeting_data)\n        context.participants = self._extract_participants(meeting_data)\n        context.decision_density = self._calculate_decision_density(meeting_data)\n        return context\n```\n\n### 實施路線圖\n\n#### 階段一：基礎架構重構 (2週)\n- [ ] 實現會議上下文感知模組\n- [ ] 開發分層提示詞引擎基礎框架\n- [ ] 創建3種基礎會議類型的適配器\n\n#### 階段二：動態策略實現 (3週)\n- [ ] 實現策略管理器\n- [ ] 開發模板組件系統\n- [ ] 整合上下文感知評估\n\n#### 階段三：自適應優化 (3週)\n- [ ] 實現強化學習優化器\n- [ ] 設置在線學習循環\n- [ ] 集成知識圖譜\n\n### 預期效益\n\n- **更智能的會議理解**：超越表面指標，理解會議本質\n- **動態適配能力**：根據會議類型自動調整記錄策略\n- **持續優化**：通過在線學習不斷改進表現\n- **更好的可解釋性**：清晰的決策過程和優化路徑\n\n### 技術棧\n\n- **核心框架**：Python 3.9+\n- **機器學習**：PyTorch, Transformers, bitsandbytes (4-bit 量化)\n- **NLP工具**：sentence-transformers, NLTK\n- **記憶體優化**：accelerate, vLLM (可選)\n- **監控工具**：psutil, GPUtil\n\n### 記憶體優化策略\n\n1. **模型量化**\n   - 使用 4-bit 量化技術\n   - 動態量化權重矩陣\n   - 啟用 Flash Attention 2 (如支援)\n\n2. **批次處理**\n   - 小批次處理輸入數據\n   - 實現記憶體監控\n   - 動態調整批次大小\n\n3. **快取機制**\n   - 使用 LRU 快取優化結果\n   - 實現提示詞模板快取\n   - 特徵向量快取\n\n4. **資源監控**\n   - 即時監控記憶體使用\n   - 動態降級機制\n   - 自動清理未使用的資源\n\n### 開發原則\n\n1. **資源效率**：優先考慮記憶體和計算效率\n2. **漸進式增強**：先實現核心功能，再逐步優化\n3. **可觀察性**：完善的監控和日誌記錄\n4. **優雅降級**：在資源受限時自動調整功能\n\n### 效能基準\n\n| 任務 | 預期記憶體使用 | 預期處理時間 |\n|------|--------------|------------|\n| 模型載入 | ~8GB | 30-60秒 |\n| 提示詞優化 | ~12GB | 5-15秒/提示 |\n| 批次處理 (n=5) | ~14GB | 20-40秒 |\n\n> **注意**：實際數值可能因系統負載和具體輸入而異\n\n### 已知限制\n\n1. **記憶體限制**：\n   - 同時載入多個大型模型可能導致記憶體不足\n   - 建議一次只載入一個模型進行推理\n\n2. **處理時間**：\n   - 複雜提示詞可能需要更長處理時間\n   - 批次處理時延遲會增加\n\n3. **建議的最佳實踐**：\n   - 實現請求佇列系統\n   - 設定處理超時機制\n   - 定期重啟長時間運行的程序以釋放記憶體\n\n## 最近更新\n\n### 2025-05-28 (最新)\n- 重構提示工程優化架構\n- 實現分層提示詞引擎\n- 新增會議上下文感知模組\n- 設計動態策略管理系統\n- 更新實施路線圖\n\n### 2025-05-27\n- 更新 README 文件，改進文檔結構和內容完整性\n- 修復評估階段文件路徑比對問題\n- 優化模型名稱處理邏輯，支援不同格式的模型名稱\n- 改進評估腳本，可選擇性評估特定模型的結果\n- 更新 `run_optimization.sh` 腳本，確保正確傳遞模型參數\n- 改進錯誤處理和日誌記錄\n- 新增模型執行時間統計功能\n- 新增策略執行時間統計功能\n- 添加 `run_all_models.sh` 腳本用於批量運行多個模型\n\n### 2025-05-27\n- 新增模型執行時間統計功能\n- 新增策略執行時間統計功能\n- 改進模型名稱處理邏輯\n- 優化錯誤處理和重試機制\n- 添加 `run_all_models.sh` 腳本用於批量運行多個模型\n\n### 2025-05-26\n- 實現模型響應時間追蹤\n- 優化模型調用過程中的錯誤處理\n- 改進重試機制，提高穩定性\n\n### 2025-05-25\n- 修復 `time` 模組導入問題\n- 修正 `model_timings` 和 `strategy_timings` 變數作用域問題\n- 更新評估結果和改進策略\n\n## 授權\n\n本項目採用 [MIT 許可證](LICENSE) 授權。",
          "生成的會議記錄（基於模板和參考文本）:\n\n\n參考:\n# 會議記錄優化工具安裝與使用指南\n\n## 環境要求\n\n- Python 3.8 或更高版本\n- CUDA 11.7 或更高版本（如需 GPU 加速）\n- 至少 16GB 系統記憶體（建議 32GB 或更多）\n- 至少 20GB 可用磁碟空間（用於模型快取）\n\n## 安裝步驟\n\n1. 克隆代碼庫：\n   ```bash\n   git clone <repository-url>\n   cd exam08_提示詞練習重啟\n   ```\n\n2. 創建並啟動虛擬環境（建議）：\n   ```bash\n   python -m venv venv\n   source venv/bin/activate  # Linux/Mac\n   # 或\n   .\\venv\\Scripts\\activate  # Windows\n   ```\n\n3. 安裝依賴：\n   ```bash\n   pip install -r requirements.txt\n   ```\n\n4. 安裝 PyTorch（如需 GPU 支援）：\n   ```bash\n   # 請根據您的 CUDA 版本選擇合適的安裝命令\n   # 例如，CUDA 11.8：\n   pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n   ```\n\n## 下載模型\n\n本工具支援多種語言模型，預設使用 `cwchang/llama3-taide-lx-8b-chat-alpha1_latest`。\n\n首次運行時，工具會自動下載模型（約 15GB）。確保您有足夠的磁碟空間和穩定的網路連接。\n\n## 使用方法\n\n### 1. 優化單個會議記錄\n\n```bash\npython scripts/optimize_meeting_minutes.py path/to/your/meeting.txt\n```\n\n### 2. 批量處理多個會議記錄\n\n```bash\n# 創建輸出目錄\nmkdir -p optimized_meetings\n\n# 處理目錄中的所有 .txt 文件\nfor f in data/meetings/*.txt; do\n    python scripts/optimize_meeting_minutes.py \"$f\" -o optimized_meetings\ndone\n```\n\n### 3. 評估優化效果\n\n```bash\n# 評估單個優化結果\npython scripts/test_optimization.py --test-dir path/to/test/files --output-dir results/evaluation\n\n# 查看評估報告\ncat results/evaluation/optimization_evaluation.json\n```\n\n## 進階選項\n\n### 使用不同的模型\n\n```bash\npython scripts/optimize_meeting_minutes.py meeting.txt --model \"jcai/llama3-taide-lx-8b-chat-alpha1_Q4_K_M\"\n```\n\n### 調整生成長度\n\n```bash\n# 增加生成長度限制\npython scripts/optimize_meeting_minutes.py meeting.txt --max-length 4096\n```\n\n## 疑難排解\n\n### 記憶體不足\n\n如果遇到記憶體不足錯誤，請嘗試：\n\n1. 減少生成長度 (`--max-length`)\n2. 使用較小的模型\n3. 增加系統交換空間\n4. 使用 CPU 模式（不推薦，速度較慢）\n\n### 模型下載問題\n\n如果模型下載失敗：\n\n1. 檢查網路連接\n2. 確保有足夠的磁碟空間\n3. 手動下載模型並指定本地路徑\n\n## 貢獻指南\n\n歡迎提交問題和拉取請求！請確保：\n\n1. 遵循現有的代碼風格\n2. 為新功能添加測試\n3. 更新相關文檔\n\n## 授權\n\n[在此添加授權信息]"
        ]
      },
      "timestamp": "2025-05-28T14:04:38.993379"
    }
  ]
}