#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
èªæ„åˆ†æ®µæ•´åˆå®Œæ•´æ¸¬è©¦è…³æœ¬
æ¸¬è©¦èªæ„åˆ†æ®µèˆ‡æœƒè­°è¨˜éŒ„å„ªåŒ–çš„å®Œæ•´æµç¨‹æ•´åˆ
"""

import os
import sys
import logging
from pathlib import Path

# æ·»åŠ  scripts ç›®éŒ„åˆ° Python è·¯å¾‘
project_root = Path(__file__).parent
scripts_dir = project_root / "scripts"
sys.path.insert(0, str(scripts_dir))

def setup_logging():
    """è¨­ç½®æ—¥èªŒ"""
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
        handlers=[
            logging.StreamHandler(),
            logging.FileHandler('test_semantic_integration_complete.log')
        ]
    )
    return logging.getLogger(__name__)

def test_semantic_modules_import():
    """æ¸¬è©¦èªæ„åˆ†æ®µæ¨¡çµ„å°å…¥"""
    logger = logging.getLogger(__name__)
    logger.info("=== æ¸¬è©¦èªæ„åˆ†æ®µæ¨¡çµ„å°å…¥ ===")
    
    try:
        from semantic_splitter import SemanticSplitter
        logger.info("âœ“ SemanticSplitter å°å…¥æˆåŠŸ")
    except ImportError as e:
        logger.error(f"âœ— SemanticSplitter å°å…¥å¤±æ•—: {e}")
        assert False
    
    try:
        from segment_quality_eval import SegmentQualityEvaluator
        logger.info("âœ“ SegmentQualityEvaluator å°å…¥æˆåŠŸ")
    except ImportError as e:
        logger.error(f"âœ— SegmentQualityEvaluator å°å…¥å¤±æ•—: {e}")
        assert False
    
    try:
        from semantic_meeting_processor import SemanticMeetingProcessor
        logger.info("âœ“ SemanticMeetingProcessor å°å…¥æˆåŠŸ")
    except ImportError as e:
        logger.error(f"âœ— SemanticMeetingProcessor å°å…¥å¤±æ•—: {e}")
        assert False
    
    assert True

def test_optimizer_with_semantic():
    """æ¸¬è©¦å„ªåŒ–å™¨èˆ‡èªæ„åˆ†æ®µæ•´åˆ"""
    logger = logging.getLogger(__name__)
    logger.info("=== æ¸¬è©¦å„ªåŒ–å™¨èˆ‡èªæ„åˆ†æ®µæ•´åˆ ===")
    
    try:
        from optimize_meeting_minutes import MeetingOptimizer
        
        # æ¸¬è©¦å•Ÿç”¨èªæ„åˆ†æ®µçš„å„ªåŒ–å™¨
        optimizer = MeetingOptimizer(
            model_name="cwchang/llama3-taide-lx-8b-chat-alpha1:latest",
            enable_semantic_segmentation=True
        )
        
        # æª¢æŸ¥èªæ„åˆ†æ®µçµ„ä»¶æ˜¯å¦æ­£ç¢ºåˆå§‹åŒ–
        if optimizer.enable_semantic_segmentation:
            logger.info("âœ“ èªæ„åˆ†æ®µåŠŸèƒ½å·²å•Ÿç”¨")
            if optimizer.semantic_splitter:
                logger.info("âœ“ SemanticSplitter åˆå§‹åŒ–æˆåŠŸ")
            else:
                logger.warning("âš  SemanticSplitter æœªåˆå§‹åŒ–")
                
            if optimizer.quality_evaluator:
                logger.info("âœ“ SegmentQualityEvaluator åˆå§‹åŒ–æˆåŠŸ")
            else:
                logger.warning("âš  SegmentQualityEvaluator æœªåˆå§‹åŒ–")
                
            if optimizer.semantic_processor:
                logger.info("âœ“ SemanticMeetingProcessor åˆå§‹åŒ–æˆåŠŸ")
            else:
                logger.warning("âš  SemanticMeetingProcessor æœªåˆå§‹åŒ–")
        else:
            logger.warning("âš  èªæ„åˆ†æ®µåŠŸèƒ½æœªå•Ÿç”¨")
        
        assert True
        
    except Exception as e:
        logger.error(f"âœ— å„ªåŒ–å™¨åˆå§‹åŒ–å¤±æ•—: {e}")
        assert False

def test_segmentation_logic():
    """æ¸¬è©¦åˆ†æ®µé‚è¼¯"""
    logger = logging.getLogger(__name__)
    logger.info("=== æ¸¬è©¦åˆ†æ®µé‚è¼¯ ===")
    
    try:
        from optimize_meeting_minutes import MeetingOptimizer
        
        optimizer = MeetingOptimizer(enable_semantic_segmentation=True)
        
        # æ¸¬è©¦çŸ­æ–‡æœ¬ï¼ˆä¸éœ€è¦åˆ†æ®µï¼‰
        short_text = "é€™æ˜¯ä¸€å€‹çŸ­æ–‡æœ¬æ¸¬è©¦ã€‚" * 10
        result = optimizer._check_and_segment_transcript(short_text)
        
        if len(result) == 1 and not result[0]['is_segmented']:
            logger.info("âœ“ çŸ­æ–‡æœ¬è™•ç†æ­£ç¢ºï¼ˆç„¡éœ€åˆ†æ®µï¼‰")
        else:
            logger.warning(f"âš  çŸ­æ–‡æœ¬è™•ç†ç•°å¸¸: {len(result)} å€‹åˆ†æ®µ")
        
        # æ¸¬è©¦é•·æ–‡æœ¬ï¼ˆéœ€è¦åˆ†æ®µï¼‰
        long_text = "é€™æ˜¯ä¸€å€‹æœƒè­°è¨˜éŒ„çš„é•·æ–‡æœ¬æ¸¬è©¦ã€‚" * 200  # ç´„ 5000 å­—å…ƒ
        result = optimizer._check_and_segment_transcript(long_text)
        
        if len(result) > 1:
            logger.info(f"âœ“ é•·æ–‡æœ¬åˆ†æ®µæˆåŠŸ: {len(result)} å€‹åˆ†æ®µ")
            for i, segment in enumerate(result):
                logger.info(f"  æ®µè½ {i+1}: {len(segment['content'])} å­—å…ƒ")
        else:
            logger.warning(f"âš  é•·æ–‡æœ¬åˆ†æ®µç•°å¸¸: åªæœ‰ {len(result)} å€‹åˆ†æ®µ")
        
        assert True
        
    except Exception as e:
        logger.error(f"âœ— åˆ†æ®µé‚è¼¯æ¸¬è©¦å¤±æ•—: {e}")
        assert False

def test_integration_with_sample_data():
    """ä½¿ç”¨å°ˆæ¡ˆç¾æœ‰é€å­—ç¨¿æ¸¬è©¦å®Œæ•´æ•´åˆ"""
    logger = logging.getLogger(__name__)
    logger.info("=== æ¸¬è©¦å®Œæ•´æ•´åˆæµç¨‹ï¼ˆä½¿ç”¨ç¾æœ‰é€å­—ç¨¿ï¼‰ ===")
    
    try:
        from optimize_meeting_minutes import MeetingOptimizer
        
        optimizer = MeetingOptimizer(enable_semantic_segmentation=True)
        
        # ä½¿ç”¨å°ˆæ¡ˆä¸­çš„å¯¦éš›é€å­—ç¨¿
        transcript_files = [
            "/Users/lanss/projects/exam08_æç¤ºè©ç·´ç¿’é‡å•Ÿ/data/transcript/ç¬¬671æ¬¡å¸‚æ”¿æœƒè­°114å¹´5æœˆ13æ—¥é€å­—ç¨¿.txt",
            "/Users/lanss/projects/exam08_æç¤ºè©ç·´ç¿’é‡å•Ÿ/data/transcript/ç¬¬672æ¬¡å¸‚æ”¿æœƒè­°114å¹´5æœˆ20æ—¥é€å­—ç¨¿.txt"
        ]
        
        reference_files = [
            "/Users/lanss/projects/exam08_æç¤ºè©ç·´ç¿’é‡å•Ÿ/data/reference/ç¬¬671æ¬¡å¸‚æ”¿æœƒè­°114å¹´5æœˆ13æ—¥æœƒè­°ç´€éŒ„.txt",
            "/Users/lanss/projects/exam08_æç¤ºè©ç·´ç¿’é‡å•Ÿ/data/reference/ç¬¬672æ¬¡å¸‚æ”¿æœƒè­°114å¹´5æœˆ20æ—¥æœƒè­°ç´€éŒ„.txt"
        ]
        
        for i, (transcript_file, reference_file) in enumerate(zip(transcript_files, reference_files)):
            logger.info(f"\n--- æ¸¬è©¦æ–‡ä»¶ {i+1}: {transcript_file.split('/')[-1]} ---")
            
            # è®€å–é€å­—ç¨¿
            try:
                with open(transcript_file, 'r', encoding='utf-8') as f:
                    transcript_content = f.read()
                logger.info(f"é€å­—ç¨¿é•·åº¦: {len(transcript_content)} å­—å…ƒ")
            except FileNotFoundError:
                logger.error(f"é€å­—ç¨¿æ–‡ä»¶ä¸å­˜åœ¨: {transcript_file}")
                continue
            
            # è®€å–åƒè€ƒæœƒè­°è¨˜éŒ„
            try:
                with open(reference_file, 'r', encoding='utf-8') as f:
                    reference_content = f.read()
                logger.info(f"åƒè€ƒè¨˜éŒ„é•·åº¦: {len(reference_content)} å­—å…ƒ")
            except FileNotFoundError:
                logger.warning(f"åƒè€ƒæ–‡ä»¶ä¸å­˜åœ¨: {reference_file}")
                reference_content = ""
            
            # åŸ·è¡Œèªæ„åˆ†æ®µæª¢æŸ¥
            segmentation_result = optimizer._check_and_segment_transcript(transcript_content)
            logger.info(f"åˆ†æ®µçµæœ: {len(segmentation_result)} å€‹åˆ†æ®µ")
            
            if len(segmentation_result) > 1:
                logger.info("âœ“ æª¢æ¸¬åˆ°å¤§å‹æ–‡æœ¬ï¼ŒæˆåŠŸè§¸ç™¼èªæ„åˆ†æ®µæµç¨‹")
                for j, segment in enumerate(segmentation_result):
                    logger.info(f"  æ®µè½ {j+1}: {len(segment['content'])} å­—å…ƒ, åˆ†æ®µæ–¹æ³•: {'èªæ„' if segment.get('is_segmented') else 'æ¨™æº–'}")
                
                # æ¸¬è©¦åˆ†æ®µè™•ç†æµç¨‹ï¼ˆæ¨¡æ“¬ _generate_minutes_batch çš„è¡Œç‚ºï¼‰
                matched_data = [{
                    'transcript': transcript_content,
                    'transcript_file': transcript_file,
                    'reference': reference_content,
                    'reference_file': reference_file
                }]
                
                logger.info("æ¨¡æ“¬èªæ„åˆ†æ®µæœƒè­°è¨˜éŒ„ç”Ÿæˆæµç¨‹...")
                # é€™è£¡å¯ä»¥æ ¹æ“šéœ€è¦æ·»åŠ æ›´è©³ç´°çš„æµç¨‹æ¸¬è©¦
                
            else:
                logger.warning(f"âš  æ–‡æœ¬é•·åº¦ {len(transcript_content)} å­—å…ƒï¼Œæœªè§¸ç™¼åˆ†æ®µï¼ˆé–¾å€¼: 4000ï¼‰")
            
            logger.info(f"âœ“ æ–‡ä»¶ {i+1} æ¸¬è©¦å®Œæˆ")
        
        assert True
        
    except Exception as e:
        logger.error(f"âœ— å®Œæ•´æ•´åˆæ¸¬è©¦å¤±æ•—: {e}")
        import traceback
        logger.error(traceback.format_exc())
        assert False

def main():
    """ä¸»å‡½æ•¸"""
    logger = setup_logging()
    logger.info("é–‹å§‹èªæ„åˆ†æ®µæ•´åˆå®Œæ•´æ¸¬è©¦")
    
    test_results = []
    
    # åŸ·è¡Œå„é …æ¸¬è©¦
    test_results.append(("æ¨¡çµ„å°å…¥æ¸¬è©¦", test_semantic_modules_import()))
    test_results.append(("å„ªåŒ–å™¨æ•´åˆæ¸¬è©¦", test_optimizer_with_semantic()))
    test_results.append(("åˆ†æ®µé‚è¼¯æ¸¬è©¦", test_segmentation_logic()))
    test_results.append(("å®Œæ•´æ•´åˆæ¸¬è©¦", test_integration_with_sample_data()))
    
    # ç¸½çµçµæœ
    logger.info("\n=== æ¸¬è©¦çµæœç¸½çµ ===")
    passed = 0
    total = len(test_results)
    
    for test_name, result in test_results:
        status = "âœ“ PASS" if result else "âœ— FAIL"
        logger.info(f"{test_name}: {status}")
        if result:
            passed += 1
    
    logger.info(f"\nç¸½é«”çµæœ: {passed}/{total} é …æ¸¬è©¦é€šé")
    
    if passed == total:
        logger.info("ğŸ‰ æ‰€æœ‰æ¸¬è©¦éƒ½é€šéï¼èªæ„åˆ†æ®µæ•´åˆæˆåŠŸï¼")
        assert True
    else:
        logger.warning(f"âš  æœ‰ {total - passed} é …æ¸¬è©¦å¤±æ•—ï¼Œéœ€è¦é€²ä¸€æ­¥æª¢æŸ¥")
        assert False

if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)
