#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
èªæ„åˆ†æ®µæ‰¹æ¬¡è™•ç†åŠŸèƒ½æ¸¬è©¦
æ¸¬è©¦æ–°å¢çš„æ‰¹æ¬¡è™•ç†å’Œå“è³ªæª¢æŸ¥åŠŸèƒ½
"""

import os
import sys
import json
import logging
import pytest
from pathlib import Path

# æ·»åŠ å°ˆæ¡ˆæ ¹ç›®éŒ„åˆ°è·¯å¾‘
project_root = os.path.abspath(os.path.dirname(__file__))
sys.path.insert(0, project_root)

def setup_logging():
    """è¨­ç½®æ—¥èªŒ"""
    logging.basicConfig(
        level=logging.INFO,
        format='[%(asctime)s] [%(levelname)s] %(message)s',
        datefmt='%Y-%m-%d %H:%M:%S'
    )
    return logging.getLogger(__name__)

def test_batch_processor_import():
    """æ¸¬è©¦æ‰¹æ¬¡è™•ç†å™¨æ¨¡çµ„å°å…¥"""
    logger = setup_logging()
    logger.info("=== æ¸¬è©¦æ‰¹æ¬¡è™•ç†å™¨æ¨¡çµ„å°å…¥ ===")
    
    try:
        from scripts.batch_semantic_processor import BatchSemanticProcessor
        logger.info("âœ“ BatchSemanticProcessor æ¨¡çµ„å°å…¥æˆåŠŸ")
        assert True
    except Exception as e:
        logger.error(f"âœ— æ¨¡çµ„å°å…¥å¤±æ•—: {e}")
        assert False, f"æ¨¡çµ„å°å…¥å¤±æ•—: {e}"

def test_quality_evaluator_coherence():
    """æ¸¬è©¦å“è³ªè©•ä¼°å™¨çš„èªæ„é€£è²«æ€§è©•ä¼°åŠŸèƒ½"""
    logger = setup_logging()
    logger.info("=== æ¸¬è©¦èªæ„é€£è²«æ€§è©•ä¼°åŠŸèƒ½ ===")
    
    try:
        from scripts.segment_quality_eval import SegmentQualityEvaluator
        
        # åˆå§‹åŒ–è©•ä¼°å™¨
        evaluator = SegmentQualityEvaluator(model_name="gemma3:12b")
        logger.info("âœ“ å“è³ªè©•ä¼°å™¨åˆå§‹åŒ–æˆåŠŸ")
        
        # æ¸¬è©¦åˆ†æ®µæ•¸æ“š
        test_segments = [
            {
                "segment_id": 1,
                "segment_text": "ä»Šå¤©çš„æœƒè­°ä¸»è¦è¨è«–ä¸‰å€‹é‡é»è­°é¡Œã€‚é¦–å…ˆæ˜¯é—œæ–¼å°ˆæ¡ˆé€²åº¦çš„æ›´æ–°ï¼Œæç¶“ç†å ±å‘Šç›®å‰é€²åº¦å·²é”70%ã€‚",
                "metadata": {"length": 45}
            },
            {
                "segment_id": 2, 
                "segment_text": "ç¬¬äºŒå€‹è­°é¡Œæ˜¯é ç®—èª¿æ•´å•é¡Œã€‚è²¡å‹™éƒ¨å»ºè­°å¢åŠ 20%çš„é ç®—ä¾†æ‡‰å°ææ–™æˆæœ¬ä¸Šæ¼²çš„å•é¡Œã€‚",
                "metadata": {"length": 42}
            }
        ]
        
        logger.info("é–‹å§‹æ¸¬è©¦èªæ„é€£è²«æ€§è©•ä¼°...")
        
        # æ¸¬è©¦èªæ„é€£è²«æ€§è©•ä¼°
        coherence_result = evaluator.evaluate_semantic_coherence(test_segments)
        
        logger.info(f"âœ“ èªæ„é€£è²«æ€§è©•ä¼°å®Œæˆ")
        logger.info(f"  å¹³å‡é€£è²«æ€§åˆ†æ•¸: {coherence_result.get('average_coherence', 0):.2f}")
        logger.info(f"  æœ‰å•é¡Œçš„åˆ†æ®µæ•¸: {coherence_result.get('poor_segments_count', 0)}")
        logger.info(f"  é€£è²«æ€§é€šéç‡: {coherence_result.get('coherence_pass_rate', 0):.1f}%")
        
        # æ¸¬è©¦æ‰¹æ¬¡å“è³ªæª¢æŸ¥
        logger.info("é–‹å§‹æ¸¬è©¦æ‰¹æ¬¡å“è³ªæª¢æŸ¥...")
        batch_result = evaluator.batch_quality_check(test_segments)
        
        logger.info(f"âœ“ æ‰¹æ¬¡å“è³ªæª¢æŸ¥å®Œæˆ")
        logger.info(f"  æ•´é«”å“è³ªåˆ†æ•¸: {batch_result['summary']['overall_quality']:.2f}")
        logger.info(f"  éœ€è¦ä¿®è¨‚: {batch_result['summary']['needs_revision']}")
        
        assert True
        
    except Exception as e:
        logger.error(f"âœ— èªæ„é€£è²«æ€§è©•ä¼°æ¸¬è©¦å¤±æ•—: {e}", exc_info=True)
        assert False, f"èªæ„é€£è²«æ€§è©•ä¼°æ¸¬è©¦å¤±æ•—: {e}"

def test_batch_processor_with_real_data():
    """ä½¿ç”¨å¯¦éš›æ•¸æ“šæ¸¬è©¦æ‰¹æ¬¡è™•ç†å™¨"""
    logger = setup_logging()
    logger.info("=== æ¸¬è©¦æ‰¹æ¬¡è™•ç†å™¨å¯¦éš›æ•¸æ“šè™•ç† ===")
    
    try:
        from scripts.batch_semantic_processor import BatchSemanticProcessor
        
        # åˆå§‹åŒ–è™•ç†å™¨
        processor = BatchSemanticProcessor(
            segmentation_model="gemma3:12b",
            evaluation_model="gemma3:12b",
            output_dir="output/test_batch_processing"
        )
        
        logger.info("âœ“ æ‰¹æ¬¡è™•ç†å™¨åˆå§‹åŒ–æˆåŠŸ")
        
        # æª¢æŸ¥æ˜¯å¦æœ‰å¯¦éš›é€å­—ç¨¿æ–‡ä»¶
        transcript_dir = Path("data/transcript")
        if not transcript_dir.exists():
            logger.warning("âš  é€å­—ç¨¿ç›®éŒ„ä¸å­˜åœ¨ï¼Œè·³éå¯¦éš›æ•¸æ“šæ¸¬è©¦")
            pytest.skip("é€å­—ç¨¿ç›®éŒ„ä¸å­˜åœ¨")
            
        transcript_files = list(transcript_dir.glob("*.txt"))
        if not transcript_files:
            logger.warning("âš  æ²’æœ‰æ‰¾åˆ°é€å­—ç¨¿æ–‡ä»¶ï¼Œè·³éå¯¦éš›æ•¸æ“šæ¸¬è©¦")
            pytest.skip("æ²’æœ‰æ‰¾åˆ°é€å­—ç¨¿æ–‡ä»¶")
        
        # é¸æ“‡ä¸€å€‹æ–‡ä»¶é€²è¡Œæ¸¬è©¦
        test_file = transcript_files[0]
        logger.info(f"æ¸¬è©¦æ–‡ä»¶: {test_file}")
        
        # è™•ç†å–®å€‹æ–‡ä»¶
        result = processor.process_transcript_file(test_file)
        
        if "error" in result:
            logger.warning(f"âš  è™•ç†çµæœåŒ…å«éŒ¯èª¤: {result['error']}")
        else:
            logger.info("âœ“ å–®å€‹æ–‡ä»¶è™•ç†æˆåŠŸ")
            logger.info(f"  æ–‡ä»¶å¤§å°: {result.get('file_size', 0)} å­—å…ƒ")
            logger.info(f"  éœ€è¦åˆ†æ®µ: {result.get('needs_segmentation', False)}")
            
            if result.get('quality_report'):
                overall_quality = result['quality_report']['summary']['overall_quality']
                logger.info(f"  æ•´é«”å“è³ªåˆ†æ•¸: {overall_quality:.2f}")
        
        assert True
        
    except Exception as e:
        logger.error(f"âœ— æ‰¹æ¬¡è™•ç†å™¨æ¸¬è©¦å¤±æ•—: {e}", exc_info=True)
        assert False, f"æ‰¹æ¬¡è™•ç†å™¨æ¸¬è©¦å¤±æ•—: {e}"

def test_integration_with_optimization():
    """æ¸¬è©¦èˆ‡å„ªåŒ–æµç¨‹çš„æ•´åˆ"""
    logger = setup_logging()
    logger.info("=== æ¸¬è©¦èˆ‡å„ªåŒ–æµç¨‹æ•´åˆ ===")
    
    try:
        # æ¸¬è©¦ run_optimization.sh ä¸­çš„èªæ„åˆ†æ®µåƒæ•¸
        import subprocess
        
        # æª¢æŸ¥è…³æœ¬æ˜¯å¦æ”¯æ´æ–°åƒæ•¸
        result = subprocess.run(
            ["bash", "run_optimization.sh", "--help"],
            capture_output=True,
            text=True,
            timeout=10
        )
        
        if "--semantic-model" in result.stdout:
            logger.info("âœ“ run_optimization.sh æ”¯æ´èªæ„åˆ†æ®µåƒæ•¸")
        else:
            logger.warning("âš  run_optimization.sh å¯èƒ½æœªå®Œå…¨æ”¯æ´èªæ„åˆ†æ®µåƒæ•¸")
        
        # æ¸¬è©¦ iterative_optimizer çš„èªæ„åˆ†æ®µæ•´åˆ
        from scripts.iterative_optimizer import MeetingOptimizer, OptimizationConfig
        
        config = OptimizationConfig(
            max_iterations=1,
            enable_semantic_segmentation=True,
            semantic_model="gemma3:12b"
        )
        
        optimizer = MeetingOptimizer(config)
        logger.info("âœ“ iterative_optimizer èªæ„åˆ†æ®µæ•´åˆæ­£å¸¸")
        
        assert True
        
    except Exception as e:
        logger.error(f"âœ— æ•´åˆæ¸¬è©¦å¤±æ•—: {e}")
        assert False

def main():
    """ä¸»æ¸¬è©¦å‡½æ•¸"""
    logger = setup_logging()
    logger.info("é–‹å§‹èªæ„åˆ†æ®µæ‰¹æ¬¡è™•ç†åŠŸèƒ½æ¸¬è©¦")
    
    tests = [
        ("æ‰¹æ¬¡è™•ç†å™¨æ¨¡çµ„å°å…¥", test_batch_processor_import),
        ("èªæ„é€£è²«æ€§è©•ä¼°åŠŸèƒ½", test_quality_evaluator_coherence),
        ("æ‰¹æ¬¡è™•ç†å™¨å¯¦éš›æ•¸æ“š", test_batch_processor_with_real_data),
        ("å„ªåŒ–æµç¨‹æ•´åˆ", test_integration_with_optimization),
    ]
    
    passed = 0
    total = len(tests)
    
    for test_name, test_func in tests:
        logger.info(f"\n{'='*60}")
        logger.info(f"åŸ·è¡Œæ¸¬è©¦: {test_name}")
        logger.info(f"{'='*60}")
        
        try:
            if test_func():
                logger.info(f"âœ… {test_name} é€šé")
                passed += 1
            else:
                logger.error(f"âŒ {test_name} å¤±æ•—")
        except Exception as e:
            logger.error(f"âŒ {test_name} åŸ·è¡Œæ™‚å‡ºéŒ¯: {e}")
            
    logger.info(f"\n{'='*60}")
    logger.info(f"æ¸¬è©¦çµæœ: {passed}/{total} é€šé")
    logger.info(f"{'='*60}")
    
    if passed == total:
        logger.info("ğŸ‰ æ‰€æœ‰èªæ„åˆ†æ®µæ‰¹æ¬¡è™•ç†åŠŸèƒ½æ¸¬è©¦é€šéï¼")
        assert True
    else:
        logger.warning(f"âš  éƒ¨åˆ†æ¸¬è©¦å¤±æ•— ({total-passed}/{total})")
        assert False

if __name__ == "__main__":
    success = main()
    exit(0 if success else 1)
